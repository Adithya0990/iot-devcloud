{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Optimizing Computer Vision Applications\n",
    "\n",
    "This tutorial shows some techniques to get better performance for computer vision applications with the Intel® Distribution of OpenVINO™ toolkit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Setup the environment variables,download model files and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "import time\n",
    "import sys                                     \n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent.parent))\n",
    "from demoTools.demoutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\r\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading models ||################\n",
      "\n",
      "========== Downloading models/public/mobilenet-ssd/mobilenet-ssd.prototxt\n",
      "... 100%, 28 KB, 56105 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading models/public/mobilenet-ssd/mobilenet-ssd.caffemodel\n",
      "... 100%, 22605 KB, 22569 KB/s, 1 seconds passed\n",
      "\n",
      "################|| Post-processing ||################\n",
      "\n",
      "################|| Downloading models ||################\n",
      "\n",
      "========== Downloading models/public/ssd300/ssd300.tar.gz\n",
      "... 100%, 95497 KB, 26977 KB/s, 3 seconds passed\n",
      "\n",
      "################|| Post-processing ||################\n",
      "\n",
      "========== Unpacking models/public/ssd300/ssd300.tar.gz\n",
      "========== Replacing text in models/public/ssd300/models/VGGNet/VOC0712Plus/SSD_300x300_ft/deploy.prototxt\n",
      "################|| Downloading models ||################\n",
      "\n",
      "========== Downloading models/public/ssd512/ssd512.tar.gz\n",
      "... 100%, 98624 KB, 26527 KB/s, 3 seconds passed\n",
      "\n",
      "################|| Post-processing ||################\n",
      "\n",
      "========== Unpacking models/public/ssd512/ssd512.tar.gz\n",
      "========== Replacing text in models/public/ssd512/models/VGGNet/VOC0712Plus/SSD_512x512/deploy.prototxt\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name mobilenet-ssd -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name ssd300 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name ssd512 -o models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models/SSD512/{FP16,FP32} \n",
    "!mkdir -p models/SSD300/{FP16,FP32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model Optimizer on the models to get IR files\n",
    "\n",
    "First, we will create the required directories, then run the model Optimizer to get the IR files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/mobilenet-ssd/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/mobilenet-ssd/FP32/\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/opt/intel/openvino/deployment_tools/model_optimizer/mo/front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/mobilenet-ssd/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.3.0-375-g332562022\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/mobilenet-ssd/FP32/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/mobilenet-ssd/FP32/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 6.27 seconds. \n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/mobilenet-ssd/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/mobilenet-ssd/FP16/\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/opt/intel/openvino/deployment_tools/model_optimizer/mo/front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/mobilenet-ssd/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.3.0-375-g332562022\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/mobilenet-ssd/FP16/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/mobilenet-ssd/FP16/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 6.86 seconds. \n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/ssd300/models/VGGNet/VOC0712Plus/SSD_300x300_ft/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.caffemodel\n",
      "\t- Path for generated IR: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD300/FP32/\n",
      "\t- IR output name: \tVGG_VOC0712Plus_SSD_300x300_ft_iter_160000\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/opt/intel/openvino/deployment_tools/model_optimizer/mo/front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/ssd300/models/VGGNet/VOC0712Plus/SSD_300x300_ft/deploy.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.3.0-375-g332562022\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD300/FP32/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.xml\n",
      "[ SUCCESS ] BIN file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD300/FP32/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.bin\n",
      "[ SUCCESS ] Total execution time: 11.53 seconds. \n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/ssd300/models/VGGNet/VOC0712Plus/SSD_300x300_ft/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.caffemodel\n",
      "\t- Path for generated IR: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD300/FP16/\n",
      "\t- IR output name: \tVGG_VOC0712Plus_SSD_300x300_ft_iter_160000\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/opt/intel/openvino/deployment_tools/model_optimizer/mo/front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/ssd300/models/VGGNet/VOC0712Plus/SSD_300x300_ft/deploy.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.3.0-375-g332562022\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD300/FP16/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.xml\n",
      "[ SUCCESS ] BIN file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD300/FP16/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.bin\n",
      "[ SUCCESS ] Total execution time: 9.45 seconds. \n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/ssd512/models/VGGNet/VOC0712Plus/SSD_512x512/VGG_VOC0712Plus_SSD_512x512_iter_240000.caffemodel\n",
      "\t- Path for generated IR: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD512/FP32/\n",
      "\t- IR output name: \tVGG_VOC0712Plus_SSD_512x512_iter_240000\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/opt/intel/openvino/deployment_tools/model_optimizer/mo/front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/ssd512/models/VGGNet/VOC0712Plus/SSD_512x512/deploy.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.3.0-375-g332562022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD512/FP32/VGG_VOC0712Plus_SSD_512x512_iter_240000.xml\n",
      "[ SUCCESS ] BIN file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD512/FP32/VGG_VOC0712Plus_SSD_512x512_iter_240000.bin\n",
      "[ SUCCESS ] Total execution time: 12.36 seconds. \n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/ssd512/models/VGGNet/VOC0712Plus/SSD_512x512/VGG_VOC0712Plus_SSD_512x512_iter_240000.caffemodel\n",
      "\t- Path for generated IR: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD512/FP16/\n",
      "\t- IR output name: \tVGG_VOC0712Plus_SSD_512x512_iter_240000\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/opt/intel/openvino/deployment_tools/model_optimizer/mo/front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/public/ssd512/models/VGGNet/VOC0712Plus/SSD_512x512/deploy.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.3.0-375-g332562022\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD512/FP16/VGG_VOC0712Plus_SSD_512x512_iter_240000.xml\n",
      "[ SUCCESS ] BIN file: /home/u26212/19nov/iot-devcloud/smart-video-workshop/optimization-tools-and-techniques/devcloud/python/models/SSD512/FP16/VGG_VOC0712Plus_SSD_512x512_iter_240000.bin\n",
      "[ SUCCESS ] Total execution time: 9.88 seconds. \n"
     ]
    }
   ],
   "source": [
    "! python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/public/mobilenet-ssd/mobilenet-ssd.caffemodel -o models/mobilenet-ssd/FP32/ --scale 256 --mean_values [127,127,127]\n",
    "! python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/public/mobilenet-ssd/mobilenet-ssd.caffemodel -o models/mobilenet-ssd/FP16/ --scale 256 --mean_values [127,127,127] --data_type FP16\n",
    "! python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/public/ssd300/models/VGGNet/VOC0712Plus/SSD_300x300_ft/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.caffemodel --input_proto models/public/ssd300/models/VGGNet/VOC0712Plus/SSD_300x300_ft/deploy.prototxt  -o models/SSD300/FP32/\n",
    "! python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/public/ssd300/models/VGGNet/VOC0712Plus/SSD_300x300_ft/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.caffemodel --input_proto models/public/ssd300/models/VGGNet/VOC0712Plus/SSD_300x300_ft/deploy.prototxt -o models/SSD300/FP16/ --data_type FP16\n",
    "! python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/public/ssd512/models/VGGNet/VOC0712Plus/SSD_512x512/VGG_VOC0712Plus_SSD_512x512_iter_240000.caffemodel --input_proto models/public/ssd512/models/VGGNet/VOC0712Plus/SSD_512x512/deploy.prototxt -o models/SSD512/FP32/\n",
    "! python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/public/ssd512/models/VGGNet/VOC0712Plus/SSD_512x512/VGG_VOC0712Plus_SSD_512x512_iter_240000.caffemodel --input_proto models/public/ssd512/models/VGGNet/VOC0712Plus/SSD_512x512/deploy.prototxt -o models/SSD512/FP16/ --data_type FP16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Tune parameters - set batch size\n",
    "\n",
    "In this section, we will see how changes in the batch size affect the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us first look at the performance numbers for the batch size 1.\n",
    "The default batch size for the Model Optimizer is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 tutorial1_batch.py -i cars_1900.mp4 -m models/mobilenet-ssd/FP32/mobilenet-ssd.xml -l /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "### Change the batch size to 2 and run the object-detection example for new batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 tutorial1_batch.py -i cars_1900.mp4 -m models/mobilenet-ssd/FP32/mobilenet-ssd.xml -l /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so  -b 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "### Run the example for different batch sizes\n",
    "\n",
    "Change the batch sizes to 8,16,32,64,128 and so on and see the performance difference in terms of the inference time.\n",
    "\n",
    "## 3. Pick the right model based on application and hardware\n",
    "\n",
    "Use/train a model with the right performance/accuracy tradeoffs. Performance differences between models can be bigger than any optimization you can do at the inference app level. Run various SSD models from the model_downloader in the car detection example which we used in the initial tutorial and observe the performance. We will run these tests on different hardware accelerators to determine how application performance depends on models as well as hardware.\n",
    "\n",
    "In the previous step we have all the models convered and ready by model Optimizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"VIDEO\"] = \"cars_1900.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Job Script \n",
    "\n",
    "We will run the workload on several DevCloud's edge compute nodes. We will send work to the edge compute nodes by submitting jobs into a queue. For each job, we will specify the type of the edge compute server that must be allocated for the job.\n",
    "\n",
    "To pass the specific variables to the Python code, we will use following arguments:\n",
    "\n",
    "* `-m`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location of the optimized models XML\n",
    "* `-i`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location of the input video\n",
    "* `-r`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output directory\n",
    "* `-d`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hardware device type (CPU, GPU, MYRIAD, HDDL or HETERO:FPGA,CPU)\n",
    "* `-n`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number of infer requests\n",
    "\n",
    "The job file will be executed directly on the edge compute node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing object_detection.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile object_detection.sh\n",
    "\n",
    "ME=`basename $0`\n",
    "\n",
    "# The default path for the job is your home directory, so we change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "# Object detection script writes output to a file inside a directory. We make sure that this directory exists.\n",
    "# The output directory is the first argument of the bash script\n",
    "while getopts 'd:f:i:r:n:m:x:?' OPTION; do\n",
    "    case \"$OPTION\" in\n",
    "    d)\n",
    "        DEVICE=$OPTARG\n",
    "        echo \"$ME is using device $OPTARG\"\n",
    "      ;;\n",
    "\n",
    "    i)\n",
    "        INPUT_FILE=$OPTARG\n",
    "        echo \"$ME is using input file $OPTARG\"\n",
    "      ;;\n",
    "    r)\n",
    "        RESULTS_BASE=$OPTARG\n",
    "        echo \"$ME is using results base $OPTARG\"\n",
    "      ;;\n",
    "    n)\n",
    "        NUM_INFER_REQS=$OPTARG\n",
    "        echo \"$ME is running $OPTARG inference requests\"\n",
    "      ;;\n",
    "    m)\n",
    "        NUM_MODEL_PATH=$OPTARG\n",
    "        echo \"$ME is running $OPTARG inference requests\"\n",
    "      ;;\n",
    "    esac  \n",
    "done\n",
    "\n",
    "RESULTS_PATH=\"${RESULTS_BASE}\"\n",
    "mkdir -p $RESULTS_PATH\n",
    "echo \"$ME is using results path $RESULTS_PATH\"\n",
    " \n",
    "# Running the object detection code\n",
    "SAMPLEPATH=$PBS_O_WORKDIR\n",
    "python3 tutorial1.py                        -m $NUM_MODEL_PATH \\\n",
    "                                            -i $INPUT_FILE \\\n",
    "                                            -o $RESULTS_PATH \\\n",
    "                                            -d $DEVICE \\\n",
    "                                            -nireq $NUM_INFER_REQS \\\n",
    "                                            -ce /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so\n",
    "\n",
    "g++ -std=c++14 ROI_writer.cpp -o ROI_writer  -lopencv_core -lopencv_videoio -lopencv_imgproc -lopencv_highgui  -fopenmp -I/opt/intel/openvino/opencv/include/ -L/opt/intel/openvino/opencv/lib/\n",
    "# Rendering the output video\n",
    "SKIPFRAME=1\n",
    "RESOLUTION=0.5\n",
    "./ROI_writer $INPUT_FILE $RESULTS_PATH $SKIPFRAME $RESOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "### Run the object detection example with different models on different devices.\n",
    "\n",
    "For simplicity of the code and in order to put more focus on the performance number, video rendering with rectangle boxes for detected objects has been separated from object detection example(tutorial1.py). The inference difference in different scenarios can be seen in the progress bar after running the sample. \n",
    "\n",
    "\n",
    "### a) CPU\n",
    "\n",
    "#### - Inferencing using **mobilenet-ssd** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4841.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8beda9871a534a6ea375476904d099fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb94197911184bb486bfb5a85718101f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7b664e1d154207b8580b8a6bb2d317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/u26212/19nov/iot-devcloud/smart-video-workshop/demoTools/demoutils.py\", line 228, in _work\n",
      "    os.remove(output_file)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'results/Core/mobilenet/pre_progress.txt'\n",
      "\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/u26212/19nov/iot-devcloud/smart-video-workshop/demoTools/demoutils.py\", line 228, in _work\n",
      "    os.remove(output_file)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'results/Core/mobilenet/i_progress.txt'\n",
      "\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/u26212/19nov/iot-devcloud/smart-video-workshop/demoTools/demoutils.py\", line 228, in _work\n",
      "    os.remove(output_file)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'results/Core/mobilenet/post_progress.txt'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_core = !qsub object_detection.sh -l nodes=1:idc001skl:tank-870:i5-6500te -F \"-r results/Core/mobilenet -d CPU -i $VIDEO -m models/mobilenet-ssd/FP32/mobilenet-ssd.xml -n 2\" -N obj_det_core\n",
    "print(job_id_core[0]) \n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('results/Core/mobilenet', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/Core/mobilenet', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/Core/mobilenet', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Inferencing using **ssd300** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4117.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39987260682648798e9708544ac18d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874fb72e58d4441dafd6ca886e0176bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1397aeca2c4d7880dc888992796b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_core = !qsub object_detection.sh -l nodes=1:idc001skl:i5-6500te -F \"-r results/Core/ssd300 -d CPU -i $VIDEO -n 2 -m models/SSD300/FP32/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.xml\" -N obj_det_core\n",
    "print(job_id_core[0]) \n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('results/Core/ssd300', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/Core/ssd300', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/Core/ssd300', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Inferencing using **ssd512** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4118.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e725396ad1d40c3927481619b4930dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee03178c62a41a3b78beb3e8b8f53a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3896d8eb49a4351a05f241cec7e32ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_core = !qsub object_detection.sh -l nodes=1:idc001skl:i5-6500te -F \"-r results/Core/ssd512 -d CPU -i $VIDEO -n 2 -m models/SSD512/FP32/VGG_VOC0712Plus_SSD_512x512_iter_240000.xml\" -N obj_det_core\n",
    "print(job_id_core[0]) \n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('results/Core/ssd512', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/Core/ssd512', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/Core/ssd512', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "### b) GPU\n",
    "\n",
    "#### - Inferencing using **mobilenet-ssd** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4119.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25e72c0eef3419e9787a7b18867ab7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f65a02b1d064b198c56328b37e928a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0dcd42a8d94ca5a2156706e13fa057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub object_detection.sh -l nodes=1:idc001skl:intel-hd-530 -F \"-r results/GPU/mobilenet -d GPU -i $VIDEO -m models/mobilenet-ssd/FP32/mobilenet-ssd.xml -n 4\" -N obj_det_gpu \n",
    "print(job_id_gpu[0]) \n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('results/GPU/mobilenet', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/GPU/mobilenet', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/GPU/mobilenet', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Inferencing using model: ssd300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4120.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fda477a6e0f46d39f79bd5e0535a875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4eeeaf829141f48b003e9efbe7119e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d475501612394d1a8a564be0adeb1c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub object_detection.sh -l nodes=1:idc001skl:intel-hd-530 -F \"-r results/GPU/ssd300 -d GPU -i $VIDEO -m models/SSD300/FP32/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.xml -n 4\" -N obj_det_gpu \n",
    "print(job_id_gpu[0]) \n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('results/GPU/ssd300', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/GPU/ssd300', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/GPU/ssd300', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Inferencing using model: ssd512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4121.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee71a3b9b6e44b8915585bc64827b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816afb50d2f34c7cb227a76e25ac7272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451712893fe14958a52afb68262c00ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub object_detection.sh -l nodes=1:idc001skl:intel-hd-530 -F \"-r results/GPU/ssd512 -d GPU -i $VIDEO -m models/SSD512/FP32/VGG_VOC0712Plus_SSD_512x512_iter_240000.xml -n 4\" -N obj_det_gpu \n",
    "print(job_id_gpu[0]) \n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('results/GPU/ssd512', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/GPU/ssd512', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/GPU/ssd512', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "### c) Intel® Movidius™ Neural Compute Stick\n",
    "\n",
    "#### - Inferencing using **mobilenet-ssd** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4122.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b31428372f4045a4111f95640ccf26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc9c42e05cc4cc8b3a305efd37f4b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2804106f2743a69cd84230686a0620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_ncs2 = !qsub object_detection.sh -l nodes=1:idc004nc2:intel-ncs2 -F \"-r results/ncs2/mobilenet -d MYRIAD -i $VIDEO -m models/mobilenet-ssd/FP16/mobilenet-ssd.xml -n 2\" -N obj_det_ncs2\n",
    "print(job_id_ncs2[0]) \n",
    "#Progress indicators\n",
    "if job_id_ncs2:\n",
    "    progressIndicator('results/ncs2/mobilenet', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/ncs2/mobilenet', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/ncs2/mobilenet', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Inferencing using model: ssd300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4123.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e883c8e730a74a34bfc241302518b2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba6edca965f4f379f9d47f480f1f377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5f973480d5450b88b76b33b1d648b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_ncs2 = !qsub object_detection.sh -l nodes=1:idc004nc2:intel-ncs2 -F \"-r results/ncs2/ssd300 -d MYRIAD -i $VIDEO -m models/SSD300/FP16/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.xml -n 8\" -N obj_det_ncs2\n",
    "print(job_id_ncs2[0]) \n",
    "#Progress indicators\n",
    "if job_id_ncs2:\n",
    "    progressIndicator('results/ncs2/ssd300', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/ncs2/ssd300', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/ncs2/ssd300', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Inferencing using model: ssd512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_ncs2 = !qsub object_detection.sh -l nodes=1:idc004nc2:intel-ncs2 -F \"-r results/ncs2/ssd512 -d MYRIAD -i $VIDEO -m models/SSD512/FP16/VGG_VOC0712Plus_SSD_512x512_iter_240000.xml -n 8\" -N obj_det_ncs2\n",
    "print(job_id_ncs2[0]) \n",
    "#Progress indicators\n",
    "if job_id_ncs2:\n",
    "    progressIndicator('results/ncs2/ssd512', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/ncs2/ssd512', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/ncs2/ssd512', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use the right data type for your target hardware and accuracy needs\n",
    "\n",
    "In this section, we will consider an example running on a GPU. FP16 operations are better optimized than FP32 on GPUs. We will run the object detection example with SSD models with data types FP16 and FP32 and observe the performance difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub object_detection.sh -l nodes=1:idc001skl:intel-hd-530 -F \"-r results/GPU/3/FP32 -d GPU -i $VIDEO -m models/mobilenet-ssd/FP32/mobilenet-ssd.xml -n 4\" -N obj_det_gpu \n",
    "print(job_id_gpu[0]) \n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('results/GPU/3/FP32', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/GPU/3/FP32', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/GPU/3/FP32', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub object_detection.sh -l nodes=1:idc001skl:intel-hd-530 -F \"-r results/GPU/3/FP16 -d GPU -i $VIDEO -m models/mobilenet-ssd/FP16/mobilenet-ssd.xml -n 4\" -N obj_det_gpu \n",
    "print(job_id_gpu[0]) \n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('results/GPU/3/FP16', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/GPU/3/FP16', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/GPU/3/FP16', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It is clear that we got better performance with FP16 models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
