{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "This lab shows how the Intel® Distribution of OpenVINO™ toolkit provides hardware abstraction to run the sample object detection application which was built in previous modules on Intel® Movidius™ Neural Compute Stick.\n",
    "\n",
    "###  Importing dependencies, Setting the Environment variables, downloading models and Generate the IR files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys                                     \n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *\n",
    "from openvino.inference_engine import IEPlugin, IENetwork\n",
    "import cv2\n",
    "# For labeling the image\n",
    "from out_process import placeBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\r\n"
     ]
    }
   ],
   "source": [
    "! /opt/intel/openvino/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.prototxt\n",
      "... 100%, 28 KB, 63465 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel\n",
      "... 100%, 22605 KB, 21133 KB/s, 1 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name mobilenet-ssd -o models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd models/object_detection/common/mobilenet-ssd  && mkdir -p FP16 && mkdir -p FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u26212/30/iot-devcloud/smart_video_workshop/HW-Acceleration-with-Movidious-NCS/Python/models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u26212/30/iot-devcloud/smart_video_workshop/HW-Acceleration-with-Movidious-NCS/Python/models/object_detection/common/mobilenet-ssd/FP16/\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u26212/30/iot-devcloud/smart_video_workshop/HW-Acceleration-with-Movidious-NCS/Python/models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.1.0-341-gc9b66a2\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u26212/30/iot-devcloud/smart_video_workshop/HW-Acceleration-with-Movidious-NCS/Python/models/object_detection/common/mobilenet-ssd/FP16/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u26212/30/iot-devcloud/smart_video_workshop/HW-Acceleration-with-Movidious-NCS/Python/models/object_detection/common/mobilenet-ssd/FP16/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 4.22 seconds. \n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u26212/30/iot-devcloud/smart_video_workshop/HW-Acceleration-with-Movidious-NCS/Python/models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u26212/30/iot-devcloud/smart_video_workshop/HW-Acceleration-with-Movidious-NCS/Python/models/object_detection/common/mobilenet-ssd/FP32\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u26212/30/iot-devcloud/smart_video_workshop/HW-Acceleration-with-Movidious-NCS/Python/models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.1.0-341-gc9b66a2\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u26212/30/iot-devcloud/smart_video_workshop/HW-Acceleration-with-Movidious-NCS/Python/models/object_detection/common/mobilenet-ssd/FP32/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u26212/30/iot-devcloud/smart_video_workshop/HW-Acceleration-with-Movidious-NCS/Python/models/object_detection/common/mobilenet-ssd/FP32/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 3.89 seconds. \n"
     ]
    }
   ],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel -o models/object_detection/common/mobilenet-ssd/FP16/ --scale 256 --mean_values [127,127,127] --data_type FP16\n",
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel -o models/object_detection/common/mobilenet-ssd/FP32 --scale 256 --mean_values [127,127,127] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "Check if the .xml and .bin files are created in folder $SV/object-detection/mobilenet-ssd/FP16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet-ssd.bin  mobilenet-ssd.mapping  mobilenet-ssd.xml\r\n"
     ]
    }
   ],
   "source": [
    " !cd models/object_detection/common/mobilenet-ssd/FP16 && ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "Now run the example application with these new IR files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "## Run the sample application on Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "#### Create Job Script \n",
    "\n",
    "We will run the workload on several DevCloud's edge compute nodes. We will send work to the edge compute nodes by submitting jobs into a queue. For each job, we will specify the type of the edge compute server that must be allocated for the job.\n",
    "\n",
    "To pass the specific variables to the Python code, we will use following arguments:\n",
    "\n",
    "* `-f`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location of the optimized models XML\n",
    "* `-i`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location of the input video\n",
    "* `-r`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output directory\n",
    "* `-d`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hardware device type (CPU, GPU, MYRIAD, HDDL or HETERO:FPGA,CPU)\n",
    "* `-n`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number of infer requests\n",
    "\n",
    "The job file will be executed directly on the edge compute node. In this exercise, we will use -d = MYRIAD as the hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting object_detection_job_ex.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile object_detection_job_ex.sh\n",
    "\n",
    "ME=`basename $0`\n",
    "\n",
    "# The default path for the job is your home directory, so we change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "# Object detection script writes output to a file inside a directory. We make sure that this directory exists.\n",
    "# The output directory is the first argument of the bash script\n",
    "while getopts 'd:f:i:r:n:?' OPTION; do\n",
    "    case \"$OPTION\" in\n",
    "    d)\n",
    "        DEVICE=$OPTARG\n",
    "        echo \"$ME is using device $OPTARG\"\n",
    "      ;;\n",
    "\n",
    "    f)\n",
    "        FP_MODEL=$OPTARG\n",
    "        echo \"$ME is using floating point model $OPTARG\"\n",
    "      ;;\n",
    "\n",
    "    i)\n",
    "        INPUT_FILE=$OPTARG\n",
    "        echo \"$ME is using input file $OPTARG\"\n",
    "      ;;\n",
    "    r)\n",
    "        RESULTS_BASE=$OPTARG\n",
    "        echo \"$ME is using results base $OPTARG\"\n",
    "      ;;\n",
    "    n)\n",
    "        NUM_INFER_REQS=$OPTARG\n",
    "        echo \"$ME is running $OPTARG inference requests\"\n",
    "      ;;\n",
    "    esac  \n",
    "done\n",
    "\n",
    "NN_MODEL=\"mobilenet-ssd.xml\"\n",
    "RESULTS_PATH=\"${RESULTS_BASE}\"\n",
    "mkdir -p $RESULTS_PATH\n",
    "echo \"$ME is using results path $RESULTS_PATH\"\n",
    "\n",
    "if [ \"$DEVICE\" = \"HETERO:FPGA,CPU\" ]; then\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/altera/aocl-pro-rte/aclrte-linux64/\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    source /opt/fpga_support_files/setup_env.sh\n",
    "    aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_bitstreams/2019R1_PL1_FP11_MobileNet_Clamp.aocx\n",
    "fi\n",
    "    \n",
    "# Running the object detection code\n",
    "SAMPLEPATH=$PBS_O_WORKDIR\n",
    "python3 tutorial1.py                        -m models/object_detection/common/mobilenet-ssd/${FP_MODEL}/${NN_MODEL}  \\\n",
    "                                            -i $INPUT_FILE \\\n",
    "                                            -o $RESULTS_PATH \\\n",
    "                                            -d $DEVICE \\\n",
    "                                            -nireq $NUM_INFER_REQS \\\n",
    "                                            -ce /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so\n",
    "\n",
    "g++ -std=c++14 ROI_writer.cpp -o ROI_writer  -lopencv_core -lopencv_videoio -lopencv_imgproc -lopencv_highgui  -fopenmp -I/opt/intel/openvino/opencv/include/ -L/opt/intel/openvino/opencv/lib/\n",
    "# Rendering the output video\n",
    "SKIPFRAME=1\n",
    "RESOLUTION=0.5\n",
    "./ROI_writer $INPUT_FILE $RESULTS_PATH $SKIPFRAME $RESOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"VIDEO\"] = \"cars_1900.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48083.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38935e15bcb6410ca40671b52b35edce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bd976c1c3643ae9b397f6e1ec145df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0716976af24e2388142065818b080a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"tutorial1.py\", line 234, in <module>\r\n",
      "    sys.exit(main() or 0)\r\n",
      "  File \"tutorial1.py\", line 131, in main\r\n",
      "    exec_net = plugin.load(network=net, num_requests=args.number_infer_requests)\r\n",
      "  File \"ie_api.pyx\", line 395, in openvino.inference_engine.ie_api.IEPlugin.load\r\n",
      "  File \"ie_api.pyx\", line 406, in openvino.inference_engine.ie_api.IEPlugin.load\r\n",
      "RuntimeError: [VPU] Unsupported network precision : FP32\r\n"
     ]
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_ncs2 = !qsub object_detection_job_ex.sh -l nodes=1:idc004nc2:intel-ncs2 -F \"-r results/NCS2/fp32 -d MYRIAD -f FP32 -i $VIDEO -n 8\" -N obj_det_ncs2\n",
    "print(job_id_ncs2[0]) \n",
    "#Progress indicators\n",
    "if job_id_ncs2:\n",
    "    progressIndicator('results/NCS2/fp32', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/NCS2/fp32', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/NCS2/fp32', 'post_progress.txt', \"Rendering\", 0, 100)\n",
    "\n",
    "while True:\n",
    "    var=job_id_ncs2[0].split(\".\")\n",
    "    file=\"obj_det_ncs2.e\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### You will get an error as Intel® Movidius™ NCS supports only FP16 format as shown above. \n",
    "\n",
    "<img src=\"FP32.png\">\n",
    "\n",
    "The Model Optimizer by default generate FP32 IR files if the data type is not particularly specified.\n",
    "\n",
    "Let's run the Model Optimizer to get IR files in FP16 format suitable for the Intel® Movidius™ NCS by setting the data_type flag to FP16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48084.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135e680e3ca34b8698e352912c990f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8461443f36c54ee9a1adcb729194ec4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab5709c4dfc44a98fb88f8b9fc05923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_ncs2 = !qsub object_detection_job_ex.sh -l nodes=1:idc004nc2:intel-ncs2 -F \"-r results/NCS2/fp16 -d MYRIAD -f FP16 -i $VIDEO -n 8\" -N obj_det_ncs2\n",
    "print(job_id_ncs2[0]) \n",
    "#Progress indicators\n",
    "if job_id_ncs2:\n",
    "    progressIndicator('results/NCS2/fp16', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/NCS2/fp16', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/NCS2/fp16', 'post_progress.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>IEI Tank (Intel  Movidius)</h2>\n",
       "    \n",
       "    <video alt=\"\" controls autoplay height=\"480\"><source src=\"results/NCS2/fp16/output.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoHTML('IEI Tank (Intel  Movidius)', \n",
    "          ['results/NCS2/fp16/output.mp4'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
