{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Intel® Distribution of OpenVINO™ toolkit hetero plugin\n",
    "\n",
    "\n",
    "    \n",
    "This example shows how to use hetero plugin to define preferences to run different network layers on different hardware types. Here, we will use the command line option to define hetero plugin usage where the layer distribution is already defined. However, hetero plugin also allows developers to customize distribution of layers execution on different hardware by specifying it in the application code.\n",
    "\n",
    "## Car detection tutorial example\n",
    "\n",
    "### 1. Importing dependencies, Setting the Environment variables and Generate the IR files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys                                     \n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *\n",
    "from openvino.inference_engine import IEPlugin, IENetwork\n",
    "import cv2\n",
    "# For labeling the image\n",
    "from out_process import placeBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\r\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.prototxt\n",
      "... 100%, 28 KB, 63697 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel\n",
      "... 100%, 22605 KB, 21680 KB/s, 1 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name mobilenet-ssd -o models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u26212/30/iot-devcloud/smart_video_workshop/hardware-heterogeneity/Python/models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u26212/30/iot-devcloud/smart_video_workshop/hardware-heterogeneity/Python/models/object_detection/common/mobilenet-ssd/FP32/\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u26212/30/iot-devcloud/smart_video_workshop/hardware-heterogeneity/Python/models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.1.0-341-gc9b66a2\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u26212/30/iot-devcloud/smart_video_workshop/hardware-heterogeneity/Python/models/object_detection/common/mobilenet-ssd/FP32/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u26212/30/iot-devcloud/smart_video_workshop/hardware-heterogeneity/Python/models/object_detection/common/mobilenet-ssd/FP32/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 4.49 seconds. \n"
     ]
    }
   ],
   "source": [
    "! python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel -o models/object_detection/common/mobilenet-ssd/FP32/ --scale 256 --mean_values [127,127,127]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. Run the car detection tutorial with hetero plugin\n",
    "\n",
    "\n",
    "#### Create Job Script \n",
    "\n",
    "We will run the workload on several DevCloud's edge compute nodes. We will send work to the edge compute nodes by submitting jobs into a queue. For each job, we will specify the type of the edge compute server that must be allocated for the job.\n",
    "\n",
    "To pass the specific variables to the Python code, we will use following arguments:\n",
    "\n",
    "* `-f`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location of the optimized models XML\n",
    "* `-i`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location of the input video\n",
    "* `-r`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output directory\n",
    "* `-d`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hardware device type (CPU, GPU, MYRIAD, HDDL or HETERO:FPGA,CPU)\n",
    "* `-n`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number of infer requests\n",
    "\n",
    "The job file will be executed directly on the edge compute node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting object_detection.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile object_detection.sh\n",
    "\n",
    "ME=`basename $0`\n",
    "\n",
    "# The default path for the job is your home directory, so we change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "# Object detection script writes output to a file inside a directory. We make sure that this directory exists.\n",
    "# The output directory is the first argument of the bash script\n",
    "while getopts 'd:f:i:r:n:?' OPTION; do\n",
    "    case \"$OPTION\" in\n",
    "    d)\n",
    "        DEVICE=$OPTARG\n",
    "        echo \"$ME is using device $OPTARG\"\n",
    "      ;;\n",
    "\n",
    "    f)\n",
    "        FP_MODEL=$OPTARG\n",
    "        echo \"$ME is using floating point model $OPTARG\"\n",
    "      ;;\n",
    "\n",
    "    i)\n",
    "        INPUT_FILE=$OPTARG\n",
    "        echo \"$ME is using input file $OPTARG\"\n",
    "      ;;\n",
    "    r)\n",
    "        RESULTS_BASE=$OPTARG\n",
    "        echo \"$ME is using results base $OPTARG\"\n",
    "      ;;\n",
    "    n)\n",
    "        NUM_INFER_REQS=$OPTARG\n",
    "        echo \"$ME is running $OPTARG inference requests\"\n",
    "      ;;\n",
    "    esac  \n",
    "done\n",
    "\n",
    "NN_MODEL=\"mobilenet-ssd.xml\"\n",
    "RESULTS_PATH=\"${RESULTS_BASE}\"\n",
    "mkdir -p $RESULTS_PATH\n",
    "echo \"$ME is using results path $RESULTS_PATH\"\n",
    "\n",
    "if [ \"$DEVICE\" = \"HETERO:FPGA,CPU\" ]; then\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/altera/aocl-pro-rte/aclrte-linux64/\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    source /opt/fpga_support_files/setup_env.sh\n",
    "    aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_bitstreams/2019R1_PL1_FP11_MobileNet_Clamp.aocx\n",
    "fi\n",
    "    \n",
    "# Running the object detection code\n",
    "SAMPLEPATH=$PBS_O_WORKDIR\n",
    "python3 tutorial1.py                        -m models/object_detection/common/mobilenet-ssd/${FP_MODEL}/${NN_MODEL}  \\\n",
    "                                            -i $INPUT_FILE \\\n",
    "                                            -o $RESULTS_PATH \\\n",
    "                                            -d $DEVICE \\\n",
    "                                            -nireq $NUM_INFER_REQS \\\n",
    "                                            -ce /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so\n",
    "\n",
    "g++ -std=c++14 ROI_writer.cpp -o ROI_writer  -lopencv_core -lopencv_videoio -lopencv_imgproc -lopencv_highgui  -fopenmp -I/opt/intel/openvino/opencv/include/ -L/opt/intel/openvino/opencv/lib/\n",
    "# Rendering the output video\n",
    "SKIPFRAME=1\n",
    "RESOLUTION=0.5\n",
    "./ROI_writer $INPUT_FILE $RESULTS_PATH $SKIPFRAME $RESOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Prioritizing running on GPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"VIDEO\"] = \"cars_1900.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48077.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4bee4ed64d4c71b123dceab2f4403d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25e277ea4ed43ce8ef693c69fe6d541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c510f1b14dc242b3bb6ff4b341865811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "########################################################################\r\n",
      "#      Date:           Fri Aug 30 06:54:47 PDT 2019\r\n",
      "#    Job ID:           48077.c003\r\n",
      "#      User:           u26212\r\n",
      "# Resources:           neednodes=1:idc001skl:intel-hd-530,nodes=1:idc001skl:intel-hd-530,walltime=01:00:00\r\n",
      "########################################################################\r\n",
      "\r\n",
      "[setupvars.sh] OpenVINO environment initialized\r\n",
      "48077.c003.SC is using results base results/GPU\r\n",
      "48077.c003.SC is using device HETERO:GPU,CPU\r\n",
      "48077.c003.SC is using floating point model FP32\r\n",
      "48077.c003.SC is using input file cars_1900.mp4\r\n",
      "48077.c003.SC is running 4 inference requests\r\n",
      "48077.c003.SC is using results path results/GPU\r\n",
      "[ INFO ] Initializing plugin for HETERO:GPU,CPU device...\r\n",
      "[ INFO ] Loading plugins for HETERO:GPU,CPU device...\r\n",
      "[ INFO ] Reading IR...\r\n",
      "[ INFO ] Loading IR to the plugin...\r\n",
      "mbox_conf_reshape is GPU\r\n",
      "conv11_mbox_conf_perm is GPU\r\n",
      "conv11_mbox_loc_perm is GPU\r\n",
      "conv13_mbox_conf_perm is GPU\r\n",
      "conv13_mbox_loc_perm is GPU\r\n",
      "conv14_2_mbox_conf_perm is GPU\r\n",
      "conv14_2_mbox_loc_perm is GPU\r\n",
      "conv15_2_mbox_conf_perm is GPU\r\n",
      "conv15_2_mbox_loc_perm is GPU\r\n",
      "conv16_2_mbox_conf_perm is GPU\r\n",
      "conv16_2_mbox_loc_perm is GPU\r\n",
      "conv17_2_mbox_conf_perm is GPU\r\n",
      "conv17_2_mbox_loc_perm is GPU\r\n",
      "[ INFO ] Starting inference in async mode, 4 requests in parallel...\r\n",
      "[ INFO ] Processing done...\r\n",
      "Video post-processing time: 40.0873 seconds\r\n",
      "\r\n",
      "########################################################################\r\n",
      "# End of output for job 48077.c003\r\n",
      "# Date: Fri Aug 30 06:57:11 PDT 2019\r\n",
      "########################################################################\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub object_detection.sh -l nodes=1:idc001skl:intel-hd-530 -F \"-r results/GPU -d HETERO:GPU,CPU -f FP32 -i $VIDEO -n 4\" -N obj_det_gpu \n",
    "print(job_id_gpu[0]) \n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('results/GPU', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/GPU', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/GPU', 'post_progress.txt', \"Rendering\", 0, 100)\n",
    "    \n",
    "while True:\n",
    "    var=job_id_gpu[0].split(\".\")\n",
    "    file=\"obj_det_gpu.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "#### b) Prioritizing running on CPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48079.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8bb294c9564298ac2a18a67ba42ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Preprocessing', style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a3f85f42474951b5b3997cb3e8d127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0514cdf22e9247e08578b31cdad09fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "########################################################################\r\n",
      "#      Date:           Fri Aug 30 06:58:29 PDT 2019\r\n",
      "#    Job ID:           48079.c003\r\n",
      "#      User:           u26212\r\n",
      "# Resources:           neednodes=1:idc001skl:intel-hd-530,nodes=1:idc001skl:intel-hd-530,walltime=01:00:00\r\n",
      "########################################################################\r\n",
      "\r\n",
      "[setupvars.sh] OpenVINO environment initialized\r\n",
      "48079.c003.SC is using results base results/Core\r\n",
      "48079.c003.SC is using device HETERO:CPU,GPU\r\n",
      "48079.c003.SC is using floating point model FP32\r\n",
      "48079.c003.SC is using input file cars_1900.mp4\r\n",
      "48079.c003.SC is running 4 inference requests\r\n",
      "48079.c003.SC is using results path results/Core\r\n",
      "[ INFO ] Initializing plugin for HETERO:CPU,GPU device...\r\n",
      "[ INFO ] Loading plugins for HETERO:CPU,GPU device...\r\n",
      "[ INFO ] Reading IR...\r\n",
      "[ INFO ] Loading IR to the plugin...\r\n",
      "mbox_conf_reshape is GPU\r\n",
      "conv11_mbox_conf_perm is GPU\r\n",
      "conv11_mbox_loc_perm is GPU\r\n",
      "conv13_mbox_conf_perm is GPU\r\n",
      "conv13_mbox_loc_perm is GPU\r\n",
      "conv14_2_mbox_conf_perm is GPU\r\n",
      "conv14_2_mbox_loc_perm is GPU\r\n",
      "conv15_2_mbox_conf_perm is GPU\r\n",
      "conv15_2_mbox_loc_perm is GPU\r\n",
      "conv16_2_mbox_conf_perm is GPU\r\n",
      "conv16_2_mbox_loc_perm is GPU\r\n",
      "conv17_2_mbox_conf_perm is GPU\r\n",
      "conv17_2_mbox_loc_perm is GPU\r\n",
      "[ INFO ] Starting inference in async mode, 4 requests in parallel...\r\n",
      "[ INFO ] Processing done...\r\n",
      "Video post-processing time: 37.043 seconds\r\n",
      "\r\n",
      "########################################################################\r\n",
      "# End of output for job 48079.c003\r\n",
      "# Date: Fri Aug 30 07:00:25 PDT 2019\r\n",
      "########################################################################\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_cpu = !qsub object_detection.sh -l nodes=1:idc001skl:intel-hd-530 -F \"-r results/Core -d HETERO:CPU,GPU -f FP32 -i $VIDEO -n 4\" -N obj_det_cpu \n",
    "print(job_id_cpu[0]) \n",
    "if job_id_cpu:\n",
    "    progressIndicator('results/Core', 'pre_progress.txt', \"Preprocessing\", 0, 100)\n",
    "    progressIndicator('results/Core', 'i_progress.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/Core', 'post_progress.txt', \"Rendering\", 0, 100)\n",
    "while True:\n",
    "    var=job_id_cpu[0].split(\".\")\n",
    "    file=\"obj_det_cpu.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Observe the performance time required to process each frame by Inference Engine. For this particular example, inference ran faster when prioritized for CPU as oppose to when GPU was the first priority.\n",
    "\n",
    " \n",
    "## Inference Engine classification sample\n",
    "\n",
    "\n",
    "Intel® Distribution of OpenVINO™ toolkit install folder (/opt/intel/openvino) includes various samples for developers to understand how Inference Engine APIs can be used. These samples have -pc flag implmented which shows per topology layer performance report. This will allow to see which layers are running on which hardware. We will run a very basic classification sample as an example in this section. We will provide car image as input to the classification sample. The output will be object labels with confidence numbers.\n",
    "\n",
    "### 1. First, get the classification model and convert that to IR using Model Optimizer\n",
    "\n",
    "For this example, we will use squeezenet model downloaded with the model downloader script while setting up the OS for the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/classification/squeezenet/1.1/caffe/squeezenet1.1.prototxt\n",
      "... 100%, 9 KB, 31206 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/classification/squeezenet/1.1/caffe/squeezenet1.1.caffemodel\n",
      "... 100%, 4834 KB, 25079 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "========= Changing input dimensions in squeezenet1.1.prototxt =========\n"
     ]
    }
   ],
   "source": [
    "! /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name squeezenet1.1 -o models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u26212/30/iot-devcloud/smart_video_workshop/hardware-heterogeneity/Python/models/classification/squeezenet/1.1/caffe/squeezenet1.1.caffemodel\n",
      "\t- Path for generated IR: \t/home/u26212/30/iot-devcloud/smart_video_workshop/hardware-heterogeneity/Python/models/squeezenet/FP32/\n",
      "\t- IR output name: \tsqueezenet1.1\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u26212/30/iot-devcloud/smart_video_workshop/hardware-heterogeneity/Python/models/classification/squeezenet/1.1/caffe/squeezenet1.1.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.1.0-341-gc9b66a2\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u26212/30/iot-devcloud/smart_video_workshop/hardware-heterogeneity/Python/models/squeezenet/FP32/squeezenet1.1.xml\n",
      "[ SUCCESS ] BIN file: /home/u26212/30/iot-devcloud/smart_video_workshop/hardware-heterogeneity/Python/models/squeezenet/FP32/squeezenet1.1.bin\n",
      "[ SUCCESS ] Total execution time: 2.36 seconds. \n"
     ]
    }
   ],
   "source": [
    "! /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/classification/squeezenet/1.1/caffe/squeezenet1.1.caffemodel -o models/squeezenet/FP32/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To display labels after classifictaion, you will need a labels file for the SqueezeNet* model. Get the available labels file from demo directory to your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /opt/intel/openvino/deployment_tools/demo/squeezenet1.1.labels models/squeezenet/FP32/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "### 2. Run classification sample with hetero plugin, prioritizing running on GPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting classification_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile classification_job.sh\n",
    "ME=`basename $0`\n",
    "\n",
    "DEVICE=$2\n",
    "\n",
    "# Object detection script writes output to a file inside a directory. We make sure that this directory exists.\n",
    "# The output directory is the first argument of the bash script\n",
    "while getopts 'd:f:i:r:n:?' OPTION; do\n",
    "    case \"$OPTION\" in\n",
    "    d)\n",
    "        DEVICE=$OPTARG\n",
    "        echo \"$ME is using device $OPTARG\"\n",
    "      ;;\n",
    "\n",
    "    f)\n",
    "        FP_MODEL=$OPTARG\n",
    "        echo \"$ME is using floating point model $OPTARG\"\n",
    "      ;;\n",
    "\n",
    "    i)\n",
    "        INPUT_FILE=$OPTARG\n",
    "        echo \"$ME is using input file $OPTARG\"\n",
    "      ;;\n",
    "    r)\n",
    "        RESULTS_BASE=$OPTARG\n",
    "        echo \"$ME is using results base $OPTARG\"\n",
    "      ;;\n",
    "    n)\n",
    "        NUM_INFER_REQS=$OPTARG\n",
    "        echo \"$ME is running $OPTARG inference requests\"\n",
    "      ;;\n",
    "    esac  \n",
    "done\n",
    "\n",
    "# The default path for the job is your home directory, so we change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "#NN_MODEL=\"mobilenet-ssd.xml\"\n",
    "RESULTS_PATH=\"${RESULTS_BASE}\"\n",
    "#mkdir -p $RESULTS_PATH\n",
    "echo \"$ME is using results path $RESULTS_PATH\"\n",
    "\n",
    "if [ \"$DEVICE\" == \"HETERO:FPGA,CPU\" ]; then\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/altera/aocl-pro-rte/aclrte-linux64/\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    source /opt/fpga_support_files/setup_env.sh\n",
    "    aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_bitstreams/2019R1_PL1_FP11_MobileNet_Clamp.aocx\n",
    "fi\n",
    "    \n",
    "# Running the object detection code\n",
    "#SAMPLEPATH=$PBS_O_WORKDIR\n",
    "python3  classification_sample.py           -i car_1.bmp \\\n",
    "                                            -m models/squeezenet/FP32/squeezenet1.1.xml \\\n",
    "                                            -d $DEVICE \\\n",
    "                                            -pc  \n",
    "\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48081.c003\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Fri Aug 30 07:02:02 PDT 2019\n",
      "#    Job ID:           48081.c003\n",
      "#      User:           u26212\n",
      "# Resources:           neednodes=1:idc001skl:intel-hd-530,nodes=1:idc001skl:intel-hd-530,walltime=01:00:00\n",
      "########################################################################\n",
      "\n",
      "[setupvars.sh] OpenVINO environment initialized\n",
      "48081.c003.SC is using results path \n",
      "[ INFO ] Loading network files:\n",
      "\tmodels/squeezenet/FP32/squeezenet1.1.xml\n",
      "\tmodels/squeezenet/FP32/squeezenet1.1.bin\n",
      "[ INFO ] Preparing input blobs\n",
      "size is 1\n",
      "[ WARNING ] Image car_1.bmp is resized from (637, 749) to (227, 227)\n",
      "[ INFO ] Batch size is 1\n",
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference (1 iterations)\n",
      "[ INFO ] Processing output blob\n",
      "[ INFO ] Top 10 results: \n",
      "Image car_1.bmp\n",
      "\n",
      "899  0.2101042 label jug\n",
      "882  0.1619387 label vacuum cleaner\n",
      "438  0.0896353 label beaker\n",
      "804  0.0695648 label dispenser\n",
      "898  0.0602503 label bottle\n",
      "503  0.0573367 label shaker\n",
      "818  0.0302897 label spot\n",
      "505  0.0283233 label coffeepot\n",
      "604  0.0228082 label hourglass\n",
      "859  0.0183771 label toaster\n",
      "\n",
      "\n",
      "[ INFO ] Average running time of one iteration: 7.297515869140625 ms\n",
      "[ INFO ] total running time of inference: 7.297515869140625 ms\n",
      "[ INFO ] Throughput: 137.03293256664924 FPS\n",
      "\n",
      "\n",
      "performance counts:\n",
      "\n",
      "subgraph0: fire6/expand3x3               EXECUTED        layerType: Convolution     realTime: 133   cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           133     microseconds        \n",
      "subgraph0: pool3                         EXECUTED        layerType: Pooling         realTime: 89    cpu:  4     execType:  pooling_gpu_ref\n",
      "TotalTime:           222     microseconds        \n",
      "subgraph0: fire3/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           222     microseconds        \n",
      "subgraph0: fire2/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           222     microseconds        \n",
      "subgraph0: fire4/expand1x1               EXECUTED        layerType: Convolution     realTime: 73    cpu:  4     execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           295     microseconds        \n",
      "subgraph0: fire2/concat                  OPTIMIZED_OUT   layerType: Concat          realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           295     microseconds        \n",
      "subgraph0: fire7/concat                  OPTIMIZED_OUT   layerType: Concat          realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           295     microseconds        \n",
      "subgraph0: fire2/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           295     microseconds        \n",
      "subgraph0: fire4/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           295     microseconds        \n",
      "subgraph0: fire7/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           295     microseconds        \n",
      "subgraph0: fire2/expand1x1               EXECUTED        layerType: Convolution     realTime: 95    cpu:  5     execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           390     microseconds        \n",
      "subgraph0: conv1                         EXECUTED        layerType: Convolution     realTime: 295   cpu:  20    execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           685     microseconds        \n",
      "subgraph0: fire5/concat                  OPTIMIZED_OUT   layerType: Concat          realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           685     microseconds        \n",
      "subgraph0: relu_conv1                    NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           685     microseconds        \n",
      "subgraph0: fire5/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           685     microseconds        \n",
      "subgraph0: fire6/expand1x1               EXECUTED        layerType: Convolution     realTime: 45    cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           730     microseconds        \n",
      "subgraph0: fire8/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           730     microseconds        \n",
      "subgraph0: fire4/expand3x3               EXECUTED        layerType: Convolution     realTime: 234   cpu:  4     execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           964     microseconds        \n",
      "subgraph0: fire9/expand3x3               EXECUTED        layerType: Convolution     realTime: 226   cpu:  5     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           1190    microseconds        \n",
      "subgraph0: fire4/concat                  OPTIMIZED_OUT   layerType: Concat          realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1190    microseconds        \n",
      "subgraph0: fire3/concat                  OPTIMIZED_OUT   layerType: Concat          realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1190    microseconds        \n",
      "subgraph0: fire6/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1190    microseconds        \n",
      "subgraph0: fire5/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 64    cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           1254    microseconds        \n",
      "subgraph0: fire8/expand3x3               EXECUTED        layerType: Convolution     realTime: 226   cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           1480    microseconds        \n",
      "subgraph0: pool5                         EXECUTED        layerType: Pooling         realTime: 60    cpu:  4     execType:  pooling_gpu_ref\n",
      "TotalTime:           1540    microseconds        \n",
      "subgraph0: fire9/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1540    microseconds        \n",
      "subgraph0: prob                          EXECUTED        layerType: SoftMax         realTime: 18    cpu:  4     execType:  softmax_gpu_bf \n",
      "TotalTime:           1558    microseconds        \n",
      "subgraph0: fire8/expand1x1               EXECUTED        layerType: Convolution     realTime: 83    cpu:  4     execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           1641    microseconds        \n",
      "subgraph0: fire4/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1641    microseconds        \n",
      "subgraph0: fire9/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1641    microseconds        \n",
      "subgraph0: fire5/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1641    microseconds        \n",
      "subgraph0: fire5/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1641    microseconds        \n",
      "subgraph0: fire9/expand1x1               EXECUTED        layerType: Convolution     realTime: 80    cpu:  4     execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           1721    microseconds        \n",
      "subgraph0: conv10                        EXECUTED        layerType: Convolution     realTime: 844   cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           2565    microseconds        \n",
      "subgraph0: fire3/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2565    microseconds        \n",
      "subgraph0: fire3/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 81    cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           2646    microseconds        \n",
      "subgraph0: fire2/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2646    microseconds        \n",
      "subgraph0: fire6/concat                  OPTIMIZED_OUT   layerType: Concat          realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2646    microseconds        \n",
      "subgraph0: fire9/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2646    microseconds        \n",
      "subgraph0: fire7/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2646    microseconds        \n",
      "subgraph0: fire3/expand3x3               EXECUTED        layerType: Convolution     realTime: 231   cpu:  5     execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           2877    microseconds        \n",
      "subgraph0: relu_conv10                   NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2877    microseconds        \n",
      "subgraph0: fire9/concat                  OPTIMIZED_OUT   layerType: Concat          realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2877    microseconds        \n",
      "subgraph0: fire8/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 62    cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           2939    microseconds        \n",
      "subgraph0: fire7/expand1x1               EXECUTED        layerType: Convolution     realTime: 46    cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           2985    microseconds        \n",
      "subgraph0: fire2/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 60    cpu:  5     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           3045    microseconds        \n",
      "subgraph0: fire6/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           3045    microseconds        \n",
      "subgraph0: fire8/concat                  OPTIMIZED_OUT   layerType: Concat          realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           3045    microseconds        \n",
      "subgraph0: fire3/expand1x1               EXECUTED        layerType: Convolution     realTime: 95    cpu:  4     execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           3140    microseconds        \n",
      "subgraph0: fire7/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 56    cpu:  10    execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           3196    microseconds        \n",
      "subgraph0: fire2/expand3x3               EXECUTED        layerType: Convolution     realTime: 412   cpu:  5     execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           3608    microseconds        \n",
      "subgraph0: fire8/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           3608    microseconds        \n",
      "subgraph0: fire4/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 42    cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           3650    microseconds        \n",
      "subgraph0: pool10                        EXECUTED        layerType: Pooling         realTime: 158   cpu:  4     execType:  pooling_gpu_ref\n",
      "TotalTime:           3808    microseconds        \n",
      "subgraph0: fire3/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           3808    microseconds        \n",
      "subgraph0: fire4/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           3808    microseconds        \n",
      "subgraph0: fire5/expand1x1               EXECUTED        layerType: Convolution     realTime: 67    cpu:  4     execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           3875    microseconds        \n",
      "subgraph0: fire6/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 43    cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           3918    microseconds        \n",
      "subgraph0: fire5/expand3x3               EXECUTED        layerType: Convolution     realTime: 237   cpu:  4     execType:  convolution_gpu_bfyx_gemm_like\n",
      "TotalTime:           4155    microseconds        \n",
      "subgraph0: fire6/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           4155    microseconds        \n",
      "subgraph0: pool1                         EXECUTED        layerType: Pooling         realTime: 149   cpu:  5     execType:  pooling_gpu_bfyx_block_opt\n",
      "TotalTime:           4304    microseconds        \n",
      "subgraph0: fire8/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           4304    microseconds        \n",
      "subgraph0: fire7/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           4304    microseconds        \n",
      "subgraph0: fire7/expand3x3               EXECUTED        layerType: Convolution     realTime: 133   cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           4437    microseconds        \n",
      "subgraph0: fire9/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 77    cpu:  4     execType:  convolution_gpu_bfyx_os_iyx_osv16\n",
      "TotalTime:           4514    microseconds        \n",
      "[ INFO ] Execution successful\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 48081.c003\n",
      "# Date: Fri Aug 30 07:02:19 PDT 2019\n",
      "########################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub classification_job.sh -l nodes=1:idc001skl:intel-hd-530 -F \"results/GPU HETERO:GPU,CPU FP32\" -N obj_det_gpu \n",
    "print(job_id_gpu[0]) \n",
    "while True:\n",
    "    var=job_id_gpu[0].split(\".\")\n",
    "    file=\"obj_det_gpu.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "perfromance counts:\n",
    "\n",
    "<img src='gpu.png'>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "### 3. Now, run with CPU first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48082.c003\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Fri Aug 30 07:03:24 PDT 2019\n",
      "#    Job ID:           48082.c003\n",
      "#      User:           u26212\n",
      "# Resources:           neednodes=1:idc001skl:intel-hd-530,nodes=1:idc001skl:intel-hd-530,walltime=01:00:00\n",
      "########################################################################\n",
      "\n",
      "[setupvars.sh] OpenVINO environment initialized\n",
      "48082.c003.SC is using results path \n",
      "[ INFO ] Loading network files:\n",
      "\tmodels/squeezenet/FP32/squeezenet1.1.xml\n",
      "\tmodels/squeezenet/FP32/squeezenet1.1.bin\n",
      "[ INFO ] Preparing input blobs\n",
      "size is 1\n",
      "[ WARNING ] Image car_1.bmp is resized from (637, 749) to (227, 227)\n",
      "[ INFO ] Batch size is 1\n",
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference (1 iterations)\n",
      "[ INFO ] Processing output blob\n",
      "[ INFO ] Top 10 results: \n",
      "Image car_1.bmp\n",
      "\n",
      "899  0.2101035 label jug\n",
      "882  0.1619391 label vacuum cleaner\n",
      "438  0.0896354 label beaker\n",
      "804  0.0695653 label dispenser\n",
      "898  0.0602502 label bottle\n",
      "503  0.0573366 label shaker\n",
      "818  0.0302898 label spot\n",
      "505  0.0283234 label coffeepot\n",
      "604  0.0228083 label hourglass\n",
      "859  0.0183770 label toaster\n",
      "\n",
      "\n",
      "[ INFO ] Average running time of one iteration: 8.653879165649414 ms\n",
      "[ INFO ] total running time of inference: 8.653879165649414 ms\n",
      "[ INFO ] Throughput: 115.55511474777529 FPS\n",
      "\n",
      "\n",
      "performance counts:\n",
      "\n",
      "subgraph0: pool1                         EXECUTED        layerType: Pooling         realTime: 349   cpu:  349   execType:  jit_avx_FP32   \n",
      "TotalTime:           349     microseconds        \n",
      "subgraph0: fire5/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 45    cpu:  45    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           394     microseconds        \n",
      "subgraph0: relu_conv10                   NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           394     microseconds        \n",
      "subgraph0: fire7/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           394     microseconds        \n",
      "subgraph0: fire8/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           394     microseconds        \n",
      "subgraph0: fire3/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           394     microseconds        \n",
      "subgraph0: fire4/expand3x3               EXECUTED        layerType: Convolution     realTime: 167   cpu:  167   execType:  jit_avx2_FP32  \n",
      "TotalTime:           561     microseconds        \n",
      "subgraph0: fire6/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           561     microseconds        \n",
      "subgraph0: fire7/concat                  EXECUTED        layerType: Concat          realTime: 1     cpu:  1     execType:  unknown_FP32   \n",
      "TotalTime:           562     microseconds        \n",
      "subgraph0: fire8/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           562     microseconds        \n",
      "subgraph0: fire3/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           562     microseconds        \n",
      "subgraph0: fire3/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           562     microseconds        \n",
      "subgraph0: conv10                        EXECUTED        layerType: Convolution     realTime: 599   cpu:  599   execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           1161    microseconds        \n",
      "subgraph0: fire9/expand1x1               EXECUTED        layerType: Convolution     realTime: 24    cpu:  24    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           1185    microseconds        \n",
      "subgraph0: fire3/expand1x1               EXECUTED        layerType: Convolution     realTime: 25    cpu:  25    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           1210    microseconds        \n",
      "subgraph0: fire9/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1210    microseconds        \n",
      "subgraph0: fire6/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 19    cpu:  19    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           1229    microseconds        \n",
      "subgraph0: fire5/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1229    microseconds        \n",
      "subgraph0: pool5                         EXECUTED        layerType: Pooling         realTime: 23    cpu:  23    execType:  jit_avx_FP32   \n",
      "TotalTime:           1252    microseconds        \n",
      "subgraph0: fire6/expand1x1               EXECUTED        layerType: Convolution     realTime: 24    cpu:  24    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           1276    microseconds        \n",
      "subgraph0: fire8/expand3x3               EXECUTED        layerType: Convolution     realTime: 178   cpu:  178   execType:  jit_avx2_FP32  \n",
      "TotalTime:           1454    microseconds        \n",
      "subgraph0: fire2/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1454    microseconds        \n",
      "subgraph0: fire9/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 43    cpu:  43    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           1497    microseconds        \n",
      "subgraph0: fire6/expand3x3               EXECUTED        layerType: Convolution     realTime: 103   cpu:  103   execType:  jit_avx2_FP32  \n",
      "TotalTime:           1600    microseconds        \n",
      "subgraph0: fire7/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 30    cpu:  30    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           1630    microseconds        \n",
      "subgraph0: fire9/expand3x3               EXECUTED        layerType: Convolution     realTime: 178   cpu:  178   execType:  jit_avx2_FP32  \n",
      "TotalTime:           1808    microseconds        \n",
      "subgraph0: fire4/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           1808    microseconds        \n",
      "subgraph0: prob_nChw8c_nchw_out_prob     EXECUTED        layerType: Reorder         realTime: 5     cpu:  5     execType:  reorder_FP32   \n",
      "TotalTime:           1813    microseconds        \n",
      "subgraph0: conv1                         EXECUTED        layerType: Convolution     realTime: 321   cpu:  321   execType:  jit_avx2_FP32  \n",
      "TotalTime:           2134    microseconds        \n",
      "subgraph0: fire5/expand1x1               EXECUTED        layerType: Convolution     realTime: 25    cpu:  25    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           2159    microseconds        \n",
      "subgraph0: fire7/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2159    microseconds        \n",
      "subgraph0: fire6/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2159    microseconds        \n",
      "subgraph0: fire2/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 33    cpu:  33    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           2192    microseconds        \n",
      "subgraph0: fire8/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2192    microseconds        \n",
      "subgraph0: fire2/expand1x1               EXECUTED        layerType: Convolution     realTime: 28    cpu:  28    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           2220    microseconds        \n",
      "subgraph0: fire5/expand3x3               EXECUTED        layerType: Convolution     realTime: 166   cpu:  166   execType:  jit_avx2_FP32  \n",
      "TotalTime:           2386    microseconds        \n",
      "subgraph0: fire4/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 23    cpu:  23    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           2409    microseconds        \n",
      "subgraph0: fire4/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2409    microseconds        \n",
      "subgraph0: fire2/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2409    microseconds        \n",
      "subgraph0: pool3                         EXECUTED        layerType: Pooling         realTime: 29    cpu:  29    execType:  jit_avx_FP32   \n",
      "TotalTime:           2438    microseconds        \n",
      "subgraph0: fire8/concat                  EXECUTED        layerType: Concat          realTime: 2     cpu:  2     execType:  unknown_FP32   \n",
      "TotalTime:           2440    microseconds        \n",
      "subgraph0: fire7/expand3x3               EXECUTED        layerType: Convolution     realTime: 103   cpu:  103   execType:  jit_avx2_FP32  \n",
      "TotalTime:           2543    microseconds        \n",
      "subgraph0: fire9/relu_squeeze1x1         NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           2543    microseconds        \n",
      "subgraph0: fire4/expand1x1               EXECUTED        layerType: Convolution     realTime: 26    cpu:  26    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           2569    microseconds        \n",
      "subgraph0: fire4/concat                  EXECUTED        layerType: Concat          realTime: 1     cpu:  1     execType:  unknown_FP32   \n",
      "TotalTime:           2570    microseconds        \n",
      "subgraph0: fire3/concat                  EXECUTED        layerType: Concat          realTime: 1     cpu:  1     execType:  unknown_FP32   \n",
      "TotalTime:           2571    microseconds        \n",
      "subgraph0: prob                          EXECUTED        layerType: SoftMax         realTime: 2457  cpu:  2457  execType:  ref_any_FP32   \n",
      "TotalTime:           5028    microseconds        \n",
      "subgraph0: fire9/concat                  EXECUTED        layerType: Concat          realTime: 1     cpu:  1     execType:  unknown_FP32   \n",
      "TotalTime:           5029    microseconds        \n",
      "subgraph0: fire2/expand3x3               EXECUTED        layerType: Convolution     realTime: 171   cpu:  171   execType:  jit_avx2_FP32  \n",
      "TotalTime:           5200    microseconds        \n",
      "subgraph0: fire5/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           5200    microseconds        \n",
      "subgraph0: fire8/expand1x1               EXECUTED        layerType: Convolution     realTime: 27    cpu:  27    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           5227    microseconds        \n",
      "subgraph0: fire9/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           5227    microseconds        \n",
      "subgraph0: fire6/concat                  EXECUTED        layerType: Concat          realTime: 1     cpu:  1     execType:  unknown_FP32   \n",
      "TotalTime:           5228    microseconds        \n",
      "subgraph0: fire3/expand3x3               EXECUTED        layerType: Convolution     realTime: 167   cpu:  167   execType:  jit_avx2_FP32  \n",
      "TotalTime:           5395    microseconds        \n",
      "subgraph0: fire8/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 37    cpu:  37    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           5432    microseconds        \n",
      "subgraph0: fire7/expand1x1               EXECUTED        layerType: Convolution     realTime: 16    cpu:  16    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           5448    microseconds        \n",
      "subgraph0: fire4/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           5448    microseconds        \n",
      "subgraph0: fire3/squeeze1x1              EXECUTED        layerType: Convolution     realTime: 46    cpu:  46    execType:  jit_avx2_1x1_FP32\n",
      "TotalTime:           5494    microseconds        \n",
      "subgraph0: relu_conv1                    NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           5494    microseconds        \n",
      "subgraph0: fire2/concat                  EXECUTED        layerType: Concat          realTime: 3     cpu:  3     execType:  unknown_FP32   \n",
      "TotalTime:           5497    microseconds        \n",
      "subgraph0: fire5/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           5497    microseconds        \n",
      "subgraph0: fire5/concat                  EXECUTED        layerType: Concat          realTime: 1     cpu:  1     execType:  unknown_FP32   \n",
      "TotalTime:           5498    microseconds        \n",
      "subgraph0: pool10                        EXECUTED        layerType: Pooling         realTime: 18    cpu:  18    execType:  jit_avx_FP32   \n",
      "TotalTime:           5516    microseconds        \n",
      "subgraph0: fire6/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           5516    microseconds        \n",
      "subgraph0: fire7/relu_expand3x3          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           5516    microseconds        \n",
      "subgraph0: fire2/relu_expand1x1          NOT_RUN         layerType: ReLU            realTime: 0     cpu:  0     execType:  undef          \n",
      "TotalTime:           5516    microseconds        \n",
      "subgraph0: out_prob                      NOT_RUN         layerType: Output          realTime: 0     cpu:  0     execType:  unknown_FP32   \n",
      "TotalTime:           5516    microseconds        \n",
      "[ INFO ] Execution successful\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 48082.c003\n",
      "# Date: Fri Aug 30 07:03:35 PDT 2019\n",
      "########################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_cpu = !qsub classification_job.sh -l nodes=1:idc001skl:intel-hd-530 -F \"results/GPU HETERO:CPU,GPU FP32\" -N obj_det_cpu\n",
    "print(job_id_cpu[0]) \n",
    "while True:\n",
    "    var=job_id_cpu[0].split(\".\")\n",
    "    file=\"obj_det_cpu.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "performance counts:\n",
    "\n",
    "\n",
    "<img src='cpu.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
