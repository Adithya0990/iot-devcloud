{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Application - C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This topic demonstrates how to use the Benchmark Application to estimate deep learning inference performance on supported devices. Performance can be measured for two inference modes: synchronous (latency-oriented) and asynchronous (throughput-oriented).\n",
    "\n",
    "### How it works\n",
    "If you run the application in the synchronous mode, it creates one infer request and executes the Infer method. If you run the application in the asynchronous mode, it creates as many infer requests as specified in the -nireq command-line parameter and executes the StartAsync method for each of them. If -nireq is not set, the demo will use the default value for specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "from demoTools.demoutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to below directory and run build samples.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Looking for C++ include unistd.h\n",
      "-- Looking for C++ include unistd.h - found\n",
      "-- Looking for C++ include stdint.h\n",
      "-- Looking for C++ include stdint.h - found\n",
      "-- Looking for C++ include sys/types.h\n",
      "-- Looking for C++ include sys/types.h - found\n",
      "-- Looking for C++ include fnmatch.h\n",
      "-- Looking for C++ include fnmatch.h - found\n",
      "-- Looking for C++ include stddef.h\n",
      "-- Looking for C++ include stddef.h - found\n",
      "-- Check size of uint32_t\n",
      "-- Check size of uint32_t - done\n",
      "-- Looking for strtoll\n",
      "-- Looking for strtoll - found\n",
      "-- Found InferenceEngine: /opt/intel/openvino_2019.1.094/deployment_tools/inference_engine/lib/intel64/libinference_engine.so (Required is at least version \"1.6\") \n",
      "-- Performing Test HAVE_CPUID_INFO\n",
      "-- Performing Test HAVE_CPUID_INFO - Success\n",
      "-- Host CPU features:\n",
      "--   3DNOW not supported\n",
      "--   3DNOWEXT not supported\n",
      "--   ABM not supported\n",
      "--   ADX supported\n",
      "--   AES supported\n",
      "--   AVX supported\n",
      "--   AVX2 supported\n",
      "--   AVX512CD supported\n",
      "--   AVX512F supported\n",
      "--   AVX512ER not supported\n",
      "--   AVX512PF not supported\n",
      "--   BMI1 supported\n",
      "--   BMI2 supported\n",
      "--   CLFSH supported\n",
      "--   CMPXCHG16B supported\n",
      "--   CX8 supported\n",
      "--   ERMS supported\n",
      "--   F16C supported\n",
      "--   FMA supported\n",
      "--   FSGSBASE supported\n",
      "--   FXSR supported\n",
      "--   HLE supported\n",
      "--   INVPCID supported\n",
      "--   LAHF supported\n",
      "--   LZCNT supported\n",
      "--   MMX supported\n",
      "--   MMXEXT not supported\n",
      "--   MONITOR supported\n",
      "--   MOVBE supported\n",
      "--   MSR supported\n",
      "--   OSXSAVE supported\n",
      "--   PCLMULQDQ supported\n",
      "--   POPCNT supported\n",
      "--   PREFETCHWT1 not supported\n",
      "--   RDRAND supported\n",
      "--   RDSEED supported\n",
      "--   RDTSCP supported\n",
      "--   RTM supported\n",
      "--   SEP supported\n",
      "--   SHA not supported\n",
      "--   SSE supported\n",
      "--   SSE2 supported\n",
      "--   SSE3 supported\n",
      "--   SSE4.1 supported\n",
      "--   SSE4.2 supported\n",
      "--   SSE4a not supported\n",
      "--   SSSE3 supported\n",
      "--   SYSCALL supported\n",
      "--   TBM not supported\n",
      "--   XOP not supported\n",
      "--   XSAVE supported\n",
      "-- TBB include: /opt/intel/openvino_2019.1.094/deployment_tools/inference_engine/external/tbb/include\n",
      "-- TBB Release lib: /opt/intel/openvino_2019.1.094/deployment_tools/inference_engine/external/tbb/lib/libtbb.so\n",
      "-- TBB Debug lib: /opt/intel/openvino_2019.1.094/deployment_tools/inference_engine/external/tbb/lib/libtbb_debug.so\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Looking for pthread_create\n",
      "-- Looking for pthread_create - not found\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/u26212/inference_engine_samples_build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target gflags_nothreads_static\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target hello_request_classification\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target hello_classification\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target format_reader\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target hello_autoresize_classification\u001b[0m\n",
      "[  0%] \u001b[32mBuilding CXX object thirdparty/gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o\u001b[0m\n",
      "[  1%] \u001b[32mBuilding CXX object thirdparty/gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object thirdparty/gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target ie_cpu_extension\u001b[0m\n",
      "[  4%] \u001b[32mBuilding CXX object hello_request_classification/CMakeFiles/hello_request_classification.dir/main.cpp.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding CXX object hello_classification/CMakeFiles/hello_classification.dir/main.cpp.o\u001b[0m\n",
      "[  5%] \u001b[32mBuilding CXX object hello_autoresize_classification/CMakeFiles/hello_autoresize_classification.dir/main.cpp.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/format_reader.cpp.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_reorg_yolo.cpp.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_simplernms.cpp.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_psroi.cpp.o\u001b[0m\n",
      "[  9%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_region_yolo.cpp.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/bmp.cpp.o\u001b[0m\n",
      "[ 11%] \u001b[32m\u001b[1mLinking CXX static library ../../intel64/Release/lib/libgflags_nothreads.a\u001b[0m\n",
      "[ 11%] Built target gflags_nothreads_static\n",
      "\u001b[35m\u001b[1mScanning dependencies of target human_pose_estimation_demo\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/opencv_wraper.cpp.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object human_pose_estimation_demo/CMakeFiles/human_pose_estimation_demo.dir/src/human_pose.cpp.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_depth_to_space.cpp.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_reverse_sequence.cpp.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CXX object human_pose_estimation_demo/CMakeFiles/human_pose_estimation_demo.dir/src/human_pose_estimator.cpp.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_space_to_depth.cpp.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/MnistUbyte.cpp.o\u001b[0m\n",
      "[ 15%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/hello_classification\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_detectionoutput_onnx.cpp.o\u001b[0m\n",
      "[ 15%] Built target hello_classification\n",
      "\u001b[35m\u001b[1mScanning dependencies of target end2end_video_analytics_opencv\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CXX object end2end_video_analytics/end2end_video_analytics_opencv/CMakeFiles/end2end_video_analytics_opencv.dir/main.cpp.o\u001b[0m\n",
      "[ 17%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/hello_request_classification\u001b[0m\n",
      "[ 17%] \u001b[32m\u001b[1mLinking CXX shared library ../../intel64/Release/lib/libformat_reader.so\u001b[0m\n",
      "[ 17%] Built target hello_request_classification\n",
      "[ 18%] \u001b[32mBuilding CXX object human_pose_estimation_demo/CMakeFiles/human_pose_estimation_demo.dir/src/peak.cpp.o\u001b[0m\n",
      "[ 18%] Built target format_reader\n",
      "\u001b[35m\u001b[1mScanning dependencies of target lenet_network_graph_builder\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CXX object lenet_network_graph_builder/CMakeFiles/lenet_network_graph_builder.dir/main.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_mvn.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/hello_autoresize_classification\u001b[0m\n",
      "[ 20%] Built target hello_autoresize_classification\n",
      "[ 21%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_priorbox.cpp.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_gather.cpp.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CXX object human_pose_estimation_demo/CMakeFiles/human_pose_estimation_demo.dir/src/render_human_pose.cpp.o\u001b[0m\n",
      "[ 21%] \u001b[32m\u001b[1mLinking CXX executable ../../intel64/Release/end2end_video_analytics_opencv\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CXX object human_pose_estimation_demo/CMakeFiles/human_pose_estimation_demo.dir/main.cpp.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_expand.cpp.o\u001b[0m\n",
      "[ 23%] Built target end2end_video_analytics_opencv\n",
      "[ 23%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/simple_copy.cpp.o\u001b[0m\n",
      "[ 24%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_range.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_roifeatureextractor_onnx.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_strided_slice.cpp.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_fill.cpp.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_argmax.cpp.o\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_pad.cpp.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_grn.cpp.o\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 28%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_list.cpp.o\u001b[0m\n",
      "[ 28%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/human_pose_estimation_demo\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_interp.cpp.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_proposal_onnx.cpp.o\u001b[0m\n",
      "[ 29%] Built target human_pose_estimation_demo\n",
      "[ 30%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_base.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/lenet_network_graph_builder\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_ctc_greedy.cpp.o\u001b[0m\n",
      "[ 31%] Built target lenet_network_graph_builder\n",
      "[ 31%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_topkrois_onnx.cpp.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_shuffle_channels.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_priorbox_clustered.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_detectionoutput.cpp.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_squeeze.cpp.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_priorgridgenerator_onnx.cpp.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_proposal.cpp.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_resample.cpp.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_normalize.cpp.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_unsqueeze.cpp.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_powerfile.cpp.o\u001b[0m\n",
      "[ 38%] \u001b[32m\u001b[1mLinking CXX shared library ../intel64/Release/lib/libcpu_extension.so\u001b[0m\n",
      "[ 38%] Built target ie_cpu_extension\n",
      "\u001b[35m\u001b[1mScanning dependencies of target benchmark_app\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target object_detection_demo_ssd_async\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target common\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target speech_sample\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target crossroad_camera_demo\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target validation_app\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target object_detection_demo\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target security_barrier_camera_demo\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object speech_sample/CMakeFiles/speech_sample.dir/main.cpp.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object benchmark_app/CMakeFiles/benchmark_app.dir/statistics_report.cpp.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding CXX object object_detection_demo_ssd_async/CMakeFiles/object_detection_demo_ssd_async.dir/main.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object object_detection_demo/CMakeFiles/object_detection_demo.dir/main.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object crossroad_camera_demo/CMakeFiles/crossroad_camera_demo.dir/main.cpp.o\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding CXX object security_barrier_camera_demo/CMakeFiles/security_barrier_camera_demo.dir/main.cpp.o\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding CXX object multichannel_demo/common/CMakeFiles/common.dir/output.cpp.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object validation_app/CMakeFiles/validation_app.dir/ClassificationProcessor.cpp.o\u001b[0m\n",
      "[ 44%] \u001b[32mBuilding CXX object benchmark_app/CMakeFiles/benchmark_app.dir/main.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object multichannel_demo/common/CMakeFiles/common.dir/perf_timer.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object multichannel_demo/common/CMakeFiles/common.dir/threading.cpp.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object multichannel_demo/common/CMakeFiles/common.dir/decoder.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/speech_sample\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object validation_app/CMakeFiles/validation_app.dir/ObjectDetectionProcessor.cpp.o\u001b[0m\n",
      "[ 47%] Built target speech_sample\n",
      "\u001b[35m\u001b[1mScanning dependencies of target calibration_tool\u001b[0m\n",
      "[ 48%] \u001b[32mBuilding CXX object calibration_tool/CMakeFiles/calibration_tool.dir/data_stats.cpp.o\u001b[0m\n",
      "[ 49%] \u001b[32mBuilding CXX object calibration_tool/CMakeFiles/calibration_tool.dir/calibrator_processors.cpp.o\u001b[0m\n",
      "[ 49%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/object_detection_demo_ssd_async\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object multichannel_demo/common/CMakeFiles/common.dir/graph.cpp.o\u001b[0m\n",
      "[ 50%] Built target object_detection_demo_ssd_async\n",
      "\u001b[35m\u001b[1mScanning dependencies of target interactive_face_detection_demo\u001b[0m\n",
      "[ 51%] \u001b[32mBuilding CXX object interactive_face_detection_demo/CMakeFiles/interactive_face_detection_demo.dir/face.cpp.o\u001b[0m\n",
      "[ 51%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/object_detection_demo\u001b[0m\n",
      "[ 51%] Built target object_detection_demo\n",
      "\u001b[35m\u001b[1mScanning dependencies of target object_detection_sample_ssd\u001b[0m\n",
      "[ 51%] \u001b[32mBuilding CXX object object_detection_sample_ssd/CMakeFiles/object_detection_sample_ssd.dir/main.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/crossroad_camera_demo\u001b[0m\n",
      "[ 52%] Built target crossroad_camera_demo\n",
      "\u001b[35m\u001b[1mScanning dependencies of target segmentation_demo\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object segmentation_demo/CMakeFiles/segmentation_demo.dir/main.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/benchmark_app\u001b[0m\n",
      "[ 53%] Built target benchmark_app\n",
      "[ 53%] \u001b[32mBuilding CXX object multichannel_demo/common/CMakeFiles/common.dir/input.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding CXX object validation_app/CMakeFiles/validation_app.dir/main.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/security_barrier_camera_demo\u001b[0m\n",
      "[ 54%] Built target security_barrier_camera_demo\n",
      "[ 54%] \u001b[32mBuilding CXX object interactive_face_detection_demo/CMakeFiles/interactive_face_detection_demo.dir/detectors.cpp.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object interactive_face_detection_demo/CMakeFiles/interactive_face_detection_demo.dir/visualizer.cpp.o\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target pedestrian_tracker_demo\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object pedestrian_tracker_demo/CMakeFiles/pedestrian_tracker_demo.dir/src/cnn.cpp.o\u001b[0m\n",
      "[ 56%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/segmentation_demo\u001b[0m\n",
      "[ 57%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/object_detection_sample_ssd\u001b[0m\n",
      "[ 57%] Built target object_detection_sample_ssd\n",
      "[ 57%] Built target segmentation_demo\n",
      "[ 57%] \u001b[32mBuilding CXX object interactive_face_detection_demo/CMakeFiles/interactive_face_detection_demo.dir/main.cpp.o\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target end2end_video_analytics_ie\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding CXX object end2end_video_analytics/end2end_video_analytics_ie/CMakeFiles/end2end_video_analytics_ie.dir/main.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32m\u001b[1mLinking CXX static library ../../intel64/Release/lib/libcommon.a\u001b[0m\n",
      "[ 59%] Built target common\n",
      "\u001b[35m\u001b[1mScanning dependencies of target mask_rcnn_demo\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object mask_rcnn_demo/CMakeFiles/mask_rcnn_demo.dir/main.cpp.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object validation_app/CMakeFiles/validation_app.dir/VOCAnnotationParser.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object validation_app/CMakeFiles/validation_app.dir/classification_set_generator.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object validation_app/CMakeFiles/validation_app.dir/image_decoder.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object calibration_tool/CMakeFiles/calibration_tool.dir/main.cpp.o\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding CXX object calibration_tool/CMakeFiles/calibration_tool.dir/__/validation_app/pugixml/pugixml.cpp.o\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding CXX object validation_app/CMakeFiles/validation_app.dir/Processor.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object pedestrian_tracker_demo/CMakeFiles/pedestrian_tracker_demo.dir/src/core.cpp.o\u001b[0m\n",
      "[ 65%] \u001b[32mBuilding CXX object validation_app/CMakeFiles/validation_app.dir/pugixml/pugixml.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32m\u001b[1mLinking CXX executable ../../intel64/Release/end2end_video_analytics_ie\u001b[0m\n",
      "[ 66%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/interactive_face_detection_demo\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 66%] Built target end2end_video_analytics_ie\n",
      "\u001b[35m\u001b[1mScanning dependencies of target style_transfer_sample\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object style_transfer_sample/CMakeFiles/style_transfer_sample.dir/main.cpp.o\u001b[0m\n",
      "[ 67%] Built target interactive_face_detection_demo\n",
      "[ 68%] \u001b[32mBuilding CXX object pedestrian_tracker_demo/CMakeFiles/pedestrian_tracker_demo.dir/src/detector.cpp.o\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding CXX object pedestrian_tracker_demo/CMakeFiles/pedestrian_tracker_demo.dir/src/distance.cpp.o\u001b[0m\n",
      "[ 68%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/mask_rcnn_demo\u001b[0m\n",
      "[ 68%] Built target mask_rcnn_demo\n",
      "\u001b[35m\u001b[1mScanning dependencies of target perfcheck\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding CXX object perfcheck/CMakeFiles/perfcheck.dir/main.cpp.o\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding CXX object calibration_tool/CMakeFiles/calibration_tool.dir/__/validation_app/ClassificationProcessor.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object pedestrian_tracker_demo/CMakeFiles/pedestrian_tracker_demo.dir/src/image_reader.cpp.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding CXX object pedestrian_tracker_demo/CMakeFiles/pedestrian_tracker_demo.dir/src/kuhn_munkres.cpp.o\u001b[0m\n",
      "[ 72%] \u001b[32mBuilding CXX object calibration_tool/CMakeFiles/calibration_tool.dir/__/validation_app/classification_set_generator.cpp.o\u001b[0m\n",
      "[ 72%] \u001b[32mBuilding CXX object pedestrian_tracker_demo/CMakeFiles/pedestrian_tracker_demo.dir/src/tracker.cpp.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object pedestrian_tracker_demo/CMakeFiles/pedestrian_tracker_demo.dir/src/utils.cpp.o\u001b[0m\n",
      "[ 74%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/validation_app\u001b[0m\n",
      "[ 74%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/style_transfer_sample\u001b[0m\n",
      "[ 74%] Built target validation_app\n",
      "[ 74%] \u001b[32mBuilding CXX object pedestrian_tracker_demo/CMakeFiles/pedestrian_tracker_demo.dir/main.cpp.o\u001b[0m\n",
      "[ 74%] Built target style_transfer_sample\n",
      "\u001b[35m\u001b[1mScanning dependencies of target classification_sample\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object classification_sample/CMakeFiles/classification_sample.dir/main.cpp.o\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target hello_shape_infer_ssd\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object hello_shape_infer_ssd/CMakeFiles/hello_shape_infer_ssd.dir/main.cpp.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding CXX object calibration_tool/CMakeFiles/calibration_tool.dir/__/validation_app/image_decoder.cpp.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding CXX object calibration_tool/CMakeFiles/calibration_tool.dir/__/validation_app/ObjectDetectionProcessor.cpp.o\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding CXX object calibration_tool/CMakeFiles/calibration_tool.dir/__/validation_app/Processor.cpp.o\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding CXX object calibration_tool/CMakeFiles/calibration_tool.dir/__/validation_app/VOCAnnotationParser.cpp.o\u001b[0m\n",
      "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/perfcheck\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target object_detection_demo_yolov3_async\u001b[0m\n",
      "[ 78%] \u001b[32mBuilding CXX object object_detection_demo_yolov3_async/CMakeFiles/object_detection_demo_yolov3_async.dir/main.cpp.o\u001b[0m\n",
      "[ 78%] Built target perfcheck\n",
      "\u001b[35m\u001b[1mScanning dependencies of target smart_classroom_demo\u001b[0m\n",
      "[ 78%] \u001b[32mBuilding CXX object smart_classroom_demo/CMakeFiles/smart_classroom_demo.dir/src/cnn.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32mBuilding CXX object smart_classroom_demo/CMakeFiles/smart_classroom_demo.dir/src/action_detector.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/classification_sample\u001b[0m\n",
      "[ 79%] Built target classification_sample\n",
      "\u001b[35m\u001b[1mScanning dependencies of target text_detection_demo\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object text_detection_demo/CMakeFiles/text_detection_demo.dir/src/image_grabber.cpp.o\u001b[0m\n",
      "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/hello_shape_infer_ssd\u001b[0m\n",
      "[ 81%] Built target hello_shape_infer_ssd\n",
      "\u001b[35m\u001b[1mScanning dependencies of target classification_sample_async\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object classification_sample_async/CMakeFiles/classification_sample_async.dir/main.cpp.o\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target super_resolution_demo\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding CXX object super_resolution_demo/CMakeFiles/super_resolution_demo.dir/main.cpp.o\u001b[0m\n",
      "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/pedestrian_tracker_demo\u001b[0m\n",
      "[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/calibration_tool\u001b[0m\n",
      "[ 85%] Built target pedestrian_tracker_demo\n",
      "\u001b[35m\u001b[1mScanning dependencies of target multi-channel-face-detection-demo\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding CXX object multichannel_demo/fd/CMakeFiles/multi-channel-face-detection-demo.dir/main.cpp.o\u001b[0m\n",
      "[ 86%] Built target calibration_tool\n",
      "\u001b[35m\u001b[1mScanning dependencies of target multi-channel-human-pose-estimation-demo\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding CXX object multichannel_demo/hpe/CMakeFiles/multi-channel-human-pose-estimation-demo.dir/postprocess.cpp.o\u001b[0m\n",
      "[ 87%] \u001b[32mBuilding CXX object text_detection_demo/CMakeFiles/text_detection_demo.dir/src/cnn.cpp.o\u001b[0m\n",
      "[ 88%] \u001b[32mBuilding CXX object multichannel_demo/hpe/CMakeFiles/multi-channel-human-pose-estimation-demo.dir/main.cpp.o\u001b[0m\n",
      "[ 88%] \u001b[32mBuilding CXX object smart_classroom_demo/CMakeFiles/smart_classroom_demo.dir/src/detector.cpp.o\u001b[0m\n",
      "[ 89%] \u001b[32mBuilding CXX object smart_classroom_demo/CMakeFiles/smart_classroom_demo.dir/src/tracker.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/object_detection_demo_yolov3_async\u001b[0m\n",
      "[ 90%] Built target object_detection_demo_yolov3_async\n",
      "[ 90%] \u001b[32mBuilding CXX object text_detection_demo/CMakeFiles/text_detection_demo.dir/src/text_detection.cpp.o\u001b[0m\n",
      "[ 91%] \u001b[32m\u001b[1mLinking CXX executable ../../intel64/Release/multi-channel-face-detection-demo\u001b[0m\n",
      "[ 91%] Built target multi-channel-face-detection-demo\n",
      "[ 92%] \u001b[32mBuilding CXX object text_detection_demo/CMakeFiles/text_detection_demo.dir/src/text_recognition.cpp.o\u001b[0m\n",
      "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/classification_sample_async\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object text_detection_demo/CMakeFiles/text_detection_demo.dir/main.cpp.o\u001b[0m\n",
      "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/super_resolution_demo\u001b[0m\n",
      "[ 92%] Built target classification_sample_async\n",
      "[ 93%] \u001b[32mBuilding CXX object smart_classroom_demo/CMakeFiles/smart_classroom_demo.dir/src/reid_gallery.cpp.o\u001b[0m\n",
      "[ 93%] Built target super_resolution_demo\n",
      "[ 93%] \u001b[32mBuilding CXX object smart_classroom_demo/CMakeFiles/smart_classroom_demo.dir/src/logger.cpp.o\u001b[0m\n",
      "[ 94%] \u001b[32mBuilding CXX object smart_classroom_demo/CMakeFiles/smart_classroom_demo.dir/src/image_grabber.cpp.o\u001b[0m\n",
      "[ 94%] \u001b[32mBuilding CXX object smart_classroom_demo/CMakeFiles/smart_classroom_demo.dir/src/align_transform.cpp.o\u001b[0m\n",
      "[ 95%] \u001b[32mBuilding CXX object multichannel_demo/hpe/CMakeFiles/multi-channel-human-pose-estimation-demo.dir/postprocessor.cpp.o\u001b[0m\n",
      "[ 96%] \u001b[32mBuilding CXX object smart_classroom_demo/CMakeFiles/smart_classroom_demo.dir/main.cpp.o\u001b[0m\n",
      "[ 96%] \u001b[32mBuilding CXX object multichannel_demo/hpe/CMakeFiles/multi-channel-human-pose-estimation-demo.dir/render_human_pose.cpp.o\u001b[0m\n",
      "[ 97%] \u001b[32mBuilding CXX object multichannel_demo/hpe/CMakeFiles/multi-channel-human-pose-estimation-demo.dir/human_pose.cpp.o\u001b[0m\n",
      "[ 97%] \u001b[32mBuilding CXX object multichannel_demo/hpe/CMakeFiles/multi-channel-human-pose-estimation-demo.dir/peak.cpp.o\u001b[0m\n",
      "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../intel64/Release/multi-channel-human-pose-estimation-demo\u001b[0m\n",
      "[ 98%] Built target multi-channel-human-pose-estimation-demo\n",
      "[ 99%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/text_detection_demo\u001b[0m\n",
      "[ 99%] Built target text_detection_demo\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/smart_classroom_demo\u001b[0m\n",
      "[100%] Built target smart_classroom_demo\n",
      "\n",
      "Build completed, you can find binaries for all samples in the /home/u26212/inference_engine_samples_build/intel64/Release subfolder.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! /opt/intel/openvino/deployment_tools/inference_engine/samples/build_samples.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Intel® Distribution of OpenVINO™ toolkit\n",
    "\n",
    "We will be using Intel® Distribution of OpenVINO™ toolkit Inference Engine (IE) to locate person in the frame.\n",
    "There are five steps involved in this task:\n",
    "\n",
    "1. Create an Intermediate Representation (IR) Model using the Model Optimizer by Intel\n",
    "2. Choose a device and create IEPlugin for the device\n",
    "3. Read the IRModel using IENetwork\n",
    "4. Load the IENetwork into the Plugin\n",
    "5. Run inference.\n",
    "\n",
    "### Creating IR Model\n",
    "\n",
    "The Model Optimizer creates Intermediate Representation (IR) models that are optimized for different end-point target devices.\n",
    "These models can be created from existing DNN models from popular frameworks (e.g. Caffe*, TF) using the Model Optimizer. \n",
    "The Intel® Distribution of OpenVINO™ toolkit includes a utility script `model_downloader.py` that you can use to download some common models. Run the following cell to see the models available through `model_downloader.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet-121\r\n",
      "densenet-161\r\n",
      "densenet-169\r\n",
      "densenet-201\r\n",
      "squeezenet1.0\r\n",
      "squeezenet1.1\r\n",
      "mtcnn-p\r\n",
      "mtcnn-r\r\n",
      "mtcnn-o\r\n",
      "mobilenet-ssd\r\n",
      "vgg19\r\n",
      "vgg16\r\n",
      "ssd512\r\n",
      "ssd300\r\n",
      "inception-resnet-v2\r\n",
      "dilation\r\n",
      "googlenet-v1\r\n",
      "googlenet-v2\r\n",
      "googlenet-v4\r\n",
      "alexnet\r\n",
      "ssd_mobilenet_v2_coco\r\n",
      "resnet-50\r\n",
      "resnet-101\r\n",
      "resnet-152\r\n",
      "googlenet-v3\r\n",
      "se-inception\r\n",
      "se-resnet-101\r\n",
      "se-resnet-152\r\n",
      "se-resnet-50\r\n",
      "se-resnext-50\r\n",
      "se-resnext-101\r\n",
      "Sphereface\r\n",
      "license-plate-recognition-barrier-0007\r\n",
      "mobilenet-v1-1.0-224\r\n",
      "mobilenet-v2\r\n",
      "faster_rcnn_inception_v2_coco\r\n",
      "deeplabv3\r\n",
      "ctpn\r\n",
      "ssd_mobilenet_v1_coco\r\n",
      "faster_rcnn_resnet101_coco\r\n",
      "mobilenet-v2-1.4-224\r\n",
      "age-gender-recognition-retail-0013\r\n",
      "age-gender-recognition-retail-0013-fp16\r\n",
      "emotions-recognition-retail-0003\r\n",
      "emotions-recognition-retail-0003-fp16\r\n",
      "face-detection-adas-0001\r\n",
      "face-detection-adas-0001-fp16\r\n",
      "face-detection-retail-0004\r\n",
      "face-detection-retail-0004-fp16\r\n",
      "face-person-detection-retail-0002\r\n",
      "face-person-detection-retail-0002-fp16\r\n",
      "face-reidentification-retail-0095\r\n",
      "face-reidentification-retail-0095-fp16\r\n",
      "facial-landmarks-35-adas-0002\r\n",
      "facial-landmarks-35-adas-0002-fp16\r\n",
      "head-pose-estimation-adas-0001\r\n",
      "head-pose-estimation-adas-0001-fp16\r\n",
      "human-pose-estimation-0001\r\n",
      "human-pose-estimation-0001-fp16\r\n",
      "landmarks-regression-retail-0009\r\n",
      "landmarks-regression-retail-0009-fp16\r\n",
      "license-plate-recognition-barrier-0001\r\n",
      "license-plate-recognition-barrier-0001-fp16\r\n",
      "pedestrian-and-vehicle-detector-adas-0001\r\n",
      "pedestrian-and-vehicle-detector-adas-0001-fp16\r\n",
      "pedestrian-detection-adas-0002\r\n",
      "pedestrian-detection-adas-0002-fp16\r\n",
      "person-attributes-recognition-crossroad-0230\r\n",
      "person-attributes-recognition-crossroad-0230-fp16\r\n",
      "person-detection-action-recognition-0005\r\n",
      "person-detection-action-recognition-0005-fp16\r\n",
      "person-detection-retail-0002\r\n",
      "person-detection-retail-0002-fp16\r\n",
      "person-detection-retail-0013\r\n",
      "person-detection-retail-0013-fp16\r\n",
      "person-reidentification-retail-0031\r\n",
      "person-reidentification-retail-0031-fp16\r\n",
      "person-reidentification-retail-0076\r\n",
      "person-reidentification-retail-0076-fp16\r\n",
      "person-reidentification-retail-0079\r\n",
      "person-reidentification-retail-0079-fp16\r\n",
      "person-vehicle-bike-detection-crossroad-0078\r\n",
      "person-vehicle-bike-detection-crossroad-0078-fp16\r\n",
      "road-segmentation-adas-0001\r\n",
      "road-segmentation-adas-0001-fp16\r\n",
      "semantic-segmentation-adas-0001\r\n",
      "semantic-segmentation-adas-0001-fp16\r\n",
      "single-image-super-resolution-1033\r\n",
      "single-image-super-resolution-1033-fp16\r\n",
      "text-detection-0002\r\n",
      "text-detection-0002-fp16\r\n",
      "vehicle-attributes-recognition-barrier-0039\r\n",
      "vehicle-attributes-recognition-barrier-0039-fp16\r\n",
      "vehicle-detection-adas-0002\r\n",
      "vehicle-detection-adas-0002-fp16\r\n",
      "vehicle-license-plate-detection-barrier-0106\r\n",
      "vehicle-license-plate-detection-barrier-0106-fp16\r\n",
      "face-detection-adas-binary-0001\r\n",
      "single-image-super-resolution-1032\r\n",
      "single-image-super-resolution-1032-fp16\r\n",
      "action-recognition-0001-encoder\r\n",
      "action-recognition-0001-encoder-fp16\r\n",
      "instance-segmentation-security-0049\r\n",
      "instance-segmentation-security-0049-fp16\r\n",
      "vehicle-detection-adas-binary-0001\r\n",
      "driver-action-recognition-adas-0002-decoder\r\n",
      "driver-action-recognition-adas-0002-decoder-fp16\r\n",
      "pedestrian-detection-adas-binary-0001\r\n",
      "person-detection-action-recognition-teacher-0002\r\n",
      "person-detection-action-recognition-teacher-0002-fp16\r\n",
      "instance-segmentation-security-0033\r\n",
      "instance-segmentation-security-0033-fp16\r\n",
      "action-recognition-0001-decoder\r\n",
      "action-recognition-0001-decoder-fp16\r\n",
      "text-recognition-0012\r\n",
      "text-recognition-0012-fp16\r\n",
      "driver-action-recognition-adas-0002-encoder\r\n",
      "driver-action-recognition-adas-0002-encoder-fp16\r\n",
      "gaze-estimation-adas-0002\r\n",
      "gaze-estimation-adas-0002-fp16\r\n",
      "resnet50-binary-0001\r\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The '!' is a special Jupyter Notebook command that allows you to run shell commands as if you are in a command line. So the above command will work straight out of the box on in a terminal (with '!' removed).\n",
    "\n",
    "Some of these downloaded models are already in the IR format, while others will require the model optimizer. In this demo, we will be using the **emotion-recognition-retail-0003** model, which is already in IR format. This model can be downloaded with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/emotions_recognition/0003/dldt/emotions-recognition-retail-0003.xml\n",
      "... 100%, 19 KB, 167 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/emotions_recognition/0003/dldt/emotions-recognition-retail-0003.bin\n",
      "... 100%, 9697 KB, 28195 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/emotions_recognition/0003/dldt/emotions-recognition-retail-0003-fp16.xml\n",
      "... 100%, 19 KB, 42608 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/emotions_recognition/0003/dldt/emotions-recognition-retail-0003-fp16.bin\n",
      "... 100%, 4848 KB, 28276 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name emotions-recognition-retail-0003 -o models/\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name emotions-recognition-retail-0003-fp16 -o models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input arguments are as follows:\n",
    "* --name : name of the model you want to download. It should be one of the models listed in the previous cell\n",
    "* -o : output directory. If this directory does not exist, it will be created for you.\n",
    "\n",
    "There are more arguments to this script and you can get the full list using the `-h` option.\n",
    "\n",
    "\n",
    "With the `-o` option set as above, this command downloads the model in the directory `models`, with the model files (.xml and .bin) located at `/Retail/object_attributes/emotions_recognition/0003/dldt`\n",
    "\n",
    "In the above case, the location is ~/benchmark_models/Retail/object_attributes/emotions_recognition/0003/dldt/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize OpenVINO env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /opt/intel/openvino/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the application with the -h option yields the following usage message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] InferenceEngine: \r\n",
      "\tAPI version ............ 1.6\r\n",
      "\tBuild .................. custom_releases/2019/R1_c9b66a26e4d65bb986bb740e73f58c6e9e84c7c2\r\n",
      "\r\n",
      "[Step 1/8] Parsing and validation of input args\r\n",
      "[ INFO ] Parsing input parameters\r\n",
      "\r\n",
      "benchmark_app [OPTION]\r\n",
      "Options:\r\n",
      "\r\n",
      "    -h                        Print a usage message\r\n",
      "    -i \"<path>\"               Required. Path to a folder with images or to image files.\r\n",
      "    -m \"<path>\"               Required. Path to an .xml file with a trained model.\r\n",
      "    -pp \"<path>\"              Optional. Path to a plugin folder.\r\n",
      "    -d \"<device>\"             Optional. Specify a target device to infer on: CPU, GPU, FPGA, HDDL or MYRIAD. Default value is CPU. Use \"-d HETERO:<comma-separated_devices_list>\" format to specify HETERO plugin. The application looks for a suitable plugin for the specified device.\r\n",
      "    -l \"<absolute_path>\"      Required for CPU custom layers. Absolute path to a shared library with the kernels implementations.\r\n",
      "          Or\r\n",
      "    -c \"<absolute_path>\"      Required for GPU custom kernels. Absolute path to an .xml file with the kernels description.\r\n",
      "    -api \"<sync/async>\"       Optional. Enable Sync/Async API. Default value is \"async\".\r\n",
      "    -niter \"<integer>\"        Optional. Number of iterations. If not specified, the number of iterations is calculated depending on a device.\r\n",
      "    -nireq \"<integer>\"        Optional. Number of infer requests. Default value is 2.\r\n",
      "    -b \"<integer>\"            Optional. Batch size value. If not specified, the batch size value is determined from Intermediate Representation.\r\n",
      "    -stream_output            Optional. Print progress as a plain text. When specified, an interactive progress bar is replaced with a multiline output.\r\n",
      "\r\n",
      "  CPU-specific performance options:\r\n",
      "    -nthreads \"<integer>\"     Optional. Number of threads to use for inference on the CPU (including HETERO cases).\r\n",
      "    -pin \"YES\"/\"NO\"           Optional. Enable (\"YES\" is default value) or disable (\"NO\") CPU threads pinning for CPU-involved inference.\r\n",
      "\r\n",
      "  Statistics dumping options:\r\n",
      "    -report_type \"<type>\"     Optional. Enable collecting statistics report. \"no_counters\" report contains configuration options specified, resulting FPS and latency. \"median_counters\" report extends \"no_counters\" report and additionally includes median PM counters values for each layer from the network. \"detailed_counters\" report extends \"median_counters\" report and additionally includes per-layer PM counters and latency for each executed infer request.\r\n",
      "    -report_folder            Optional. Path to a folder where statistics report is stored.\r\n",
      "    -exec_graph_path          Optional. Path to a file where to store executable graph information serialized.\r\n"
     ]
    }
   ],
   "source": [
    "! $HOME/inference_engine_samples_build/intel64/Release/benchmark_app -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating job file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting benchmark_app.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile benchmark_app.sh\n",
    "set -x\n",
    "INPUT_FILE=$1\n",
    "FP_MODEL=$2\n",
    "DEVICE=$3\n",
    "API=$4\n",
    "\n",
    "cd $PBS_O_WORKDIR\n",
    "export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:~/inference_engine_samples_build/intel64/Release/\n",
    "\n",
    "if [ \"$FP_MODEL\" == \"FP16\" ]; then\n",
    "  FPEXT='-fp16'\n",
    "fi\n",
    "\n",
    "echo $INPUT_FILE\n",
    "\n",
    "$HOME/inference_engine_samples_build/intel64/Release/benchmark_app \\\n",
    "-m models/Retail/object_attributes/emotions_recognition/0003/dldt/emotions-recognition-retail-0003${FPEXT}.xml \\\n",
    "-i $INPUT_FILE \\\n",
    "-d $DEVICE \\\n",
    "-api $API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u26212\r\n"
     ]
    }
   ],
   "source": [
    "!echo $HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     35      properties = idc001skl,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,1gbe\r\n",
      "     15      properties = idc002mx8,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,hddl-r,iei-mustang-v100-mx8\r\n",
      "     18      properties = idc003a10,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,hddl-f,iei-mustang-f100-a10\r\n",
      "     23      properties = idc004nc2,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,ncs,intel-ncs2\r\n",
      "      5      properties = idc006kbl,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "     16      properties = idc007xv5,compnode,iei,tank-870,intel-xeon,e3-1268l-v5,skylake,intel-hd-p530,ram32gb,net1gbe\r\n",
      "     15      properties = idc008u2g,compnode,up-squared,grove,intel-atom,e3950,apollo-lake,intel-hd-505,ram4gb,net1gbe,ncs,intel-ncs2\r\n",
      "      1      properties = idc009jkl,compnode,jwip,intel-core,i5-7500,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc010jal,compnode,jwip,intel-atom,e3950,apollo-lake,intel-hd-505,ram4gb,net1gbe\r\n",
      "      2      properties = idc012ros,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc013agg,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc014col,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc015r2,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n"
     ]
    }
   ],
   "source": [
    "!pbsnodes | grep compnode | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the properties describe the node, and number on the left is the number of available nodes of that architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you want to use your own image, change the environment variable 'IMAGE' in the following cell from \"~/benchmark_app/sample_image.png\" to the full path of your uploaded image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u26212/temp/adi/iot-devcloud/benchmark_app/emotions.jpg\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"IMAGE\"] = os.getcwd()+\"/emotions.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job queue submissinon\n",
    "\n",
    "Each of the cells below will submit a job to different edge compute nodes.\n",
    "The output of the cell is the `JobID` of your job, which you can use to track progress of a job.\n",
    "\n",
    "**Note** You can submit all jobs at once or follow one at a time. \n",
    "\n",
    "After submission, it will go into a queue and run as soon as the requested compute resources become available. \n",
    "(tip: **shift+enter** will run the cell and automatically move you to the next cell. So you can hit **shift+enter** multiple times to quickly run multiple cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The log files with output are stored in the below location.\n",
    "~/inference_engine_samples_build/intel64/Release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the default time for the application to run and provide output, i.e Latency and Throughput values, the output logs will be generated 60 seconds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with an Intel® CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel® Core™ i5-6500TE processor</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel CPU...\")\n",
    "job_id_cpu = !qsub benchmark_app.sh -l nodes=1:idc001skl:intel-hd-530 -F \"$IMAGE FP16 CPU async\" -N benchmark_cpu\n",
    "print(job_id_cpu[0]) \n",
    "while True:\n",
    "    var=job_id_cpu[0].split(\".\")\n",
    "    file=\"benchmark_cpu.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel CPU... core-FP32\")\n",
    "job_id_cpu32 = !qsub benchmark_app.sh -l nodes=1:idc001skl:intel-hd-530 -F \"$IMAGE FP32 CPU async\" -N benchmark_cpu32\n",
    "print(job_id_cpu32[0]) \n",
    "while True:\n",
    "    var=job_id_cpu32[0].split(\".\")\n",
    "    file=\"benchmark_cpu32.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Xeon® CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88178/Intel-Xeon-Processor-E3-1268L-v5-8M-Cache-2-40-GHz-\">Intel® \n",
    "    Xeon® Processor E3-1268L v5</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel Xeon CPU...\")\n",
    "job_id_xeon = !qsub benchmark_app.sh -l nodes=1:tank-870:e3-1268l-v5 -F \"$IMAGE FP32 CPU async\" -N benchmark_xeon\n",
    "print(job_id_xeon[0]) \n",
    "while True:\n",
    "    var=job_id_xeon[0].split(\".\")\n",
    "    file=\"benchmark_xeon.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel Xeon CPU FP16...\")\n",
    "job_id_xeon16 = !qsub benchmark_app.sh -l nodes=1:tank-870:e3-1268l-v5 -F \"$IMAGE FP16 CPU async\" -N benchmark_xeon16\n",
    "print(job_id_xeon16[0]) \n",
    "while True:\n",
    "    var=job_id_xeon16[0].split(\".\")\n",
    "    file=\"benchmark_xeon16.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Core CPU and using the onboard Intel® GPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel® Core i5-6500TE</a>. The inference workload will run on the Intel® HD Graphics 530 card integrated with the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job to Intel GPU...\n",
      "56780.c003\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Mon Sep 30 01:54:36 PDT 2019\n",
      "#    Job ID:           56780.c003\n",
      "#      User:           u26212\n",
      "# Resources:           neednodes=1:tank-870:i5-6500te,nodes=1:tank-870:i5-6500te,walltime=01:00:00\n",
      "########################################################################\n",
      "\n",
      "[setupvars.sh] OpenVINO environment initialized\n",
      "/home/u26212/temp/adi/iot-devcloud/benchmark_app/emotions.jpg\n",
      "[ INFO ] InferenceEngine: \n",
      "\tAPI version ............ 1.6\n",
      "\tBuild .................. custom_releases/2019/R1_c9b66a26e4d65bb986bb740e73f58c6e9e84c7c2\n",
      "\n",
      "[Step 1/8] Parsing and validation of input args\n",
      "[ INFO ] Parsing input parameters\n",
      "[ INFO ] Files were added: 1\n",
      "[ INFO ]     /home/u26212/temp/adi/iot-devcloud/benchmark_app/emotions.jpg\n",
      "Progress: [....................] 100.00% done\n",
      "\n",
      "[Step 2/8] Loading plugin\n",
      "[ INFO ] \n",
      "\tAPI version ............ 1.6\n",
      "\tBuild .................. 22443\n",
      "\tDescription ....... clDNNPlugin\n",
      "Progress: [....................] 100.00% done\n",
      "\n",
      "[Step 3/8] Read IR network\n",
      "[ INFO ] Loading network files\n",
      "[ INFO ] Network batch size: 1, precision: FP32\n",
      "Progress: [....................] 100.00% done\n",
      "\n",
      "[Step 4/8] Configure input & output of the model\n",
      "[ INFO ] Preparing output blobs\n",
      "Progress: [....................] 100.00% done\n",
      "\n",
      "[Step 5/8] Loading model to the plugin \n",
      "Progress: [....................] 100.00% done\n",
      "\n",
      "[Step 6/8] Create infer requests and fill input blobs with images\n",
      "[ INFO ] Infer Request 0 created\n",
      "[ INFO ] Network Input dimensions (NCHW): 1 3 64 64 \n",
      "[ INFO ] Prepare image /home/u26212/temp/adi/iot-devcloud/benchmark_app/emotions.jpg\n",
      "[ WARNING ] Image is resized from (600, 400) to (64, 64)\n",
      "[ INFO ] Infer Request 1 created\n",
      "[ INFO ] Network Input dimensions (NCHW): 1 3 64 64 \n",
      "[ INFO ] Prepare image /home/u26212/temp/adi/iot-devcloud/benchmark_app/emotions.jpg\n",
      "[ WARNING ] Image is resized from (600, 400) to (64, 64)\n",
      "Progress: [....................] 100.00% done\n",
      "\n",
      "[Step 7/8] \n",
      "Start inference asynchronously (60000.00 ms duration, 2 inference requests in parallel)\n",
      "Progress: [....................] 100.00% done19.00% done: [...                 ] 19.60% doneess: [.......             ] 36.70% done      ] 50.90% donerogress: [............        ] 61.40% done   ] 74.60% done70% done    ] 82.70% done...........   ] 86.70% done0% done..................  ] 93.90% done............... ] 97.20% done\n",
      "\n",
      "[Step 8/8] Dump statistics report\n",
      "[ INFO ] Statistics collecting was not requested. No reports are dumped.\n",
      "Progress: [....................] 100.00% done\n",
      "\n",
      "Latency: 2.39 ms\n",
      "Throughput: 794.81 FPS\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 56780.c003\n",
      "# Date: Mon Sep 30 01:55:46 PDT 2019\n",
      "########################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Submitting job to Intel GPU...\")\n",
    "job_id_gpu = !qsub benchmark_app.sh -l nodes=1:tank-870:i5-6500te -F \"$IMAGE FP16 GPU async\" -N benchmark_gpu\n",
    "print(job_id_gpu[0]) \n",
    "while True:\n",
    "    var=job_id_gpu[0].split(\".\")\n",
    "    file=\"benchmark_gpu.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel GPU...\")\n",
    "job_id_gpu32 = !qsub benchmark_app.sh -l nodes=1:tank-870:i5-6500te -F \"$IMAGE FP32 GPU async\" -N benchmark_gpu32\n",
    "print(job_id_gpu32[0]) \n",
    "while True:\n",
    "    var=job_id_gpu32[0].split(\".\")\n",
    "    file=\"benchmark_gpu32.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IEI Mustang-V100-MX8 ( Intel® Movidius™ Myriad™ X Vision Processing Unit (VPU))\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a>. The inference workload will run on an <a \n",
    "    href=\"https://www.ieiworld.com/mustang-v100/en/\">IEI Mustang-V100-MX8 </a>accelerator installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel VPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_hddl = !qsub benchmark_app.sh -l nodes=1:tank-870:i5-6500te:iei-mustang-v100-mx8 -F \"$IMAGE FP16 HDDL async\" -N benchmark_hddl\n",
    "print(job_id_hddl[0])\n",
    "while True:\n",
    "    var=job_id_hddl[0].split(\".\")\n",
    "    file=\"benchmark_hddl.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the jobs are done\n",
    "\n",
    "To check on the jobs that were submitted, use the `qstat` command.\n",
    "\n",
    "We have created a custom Jupyter widget  to get live qstat update.\n",
    "Run the following cell to bring it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the jobs you have submitted (referenced by `Job ID` that gets displayed right after you submit the job).\n",
    "There should also be an extra job in the queue \"jupyterhub\": this job runs your current Jupyter Notebook session.\n",
    "\n",
    "The 'S' column shows the current status. \n",
    "- If it is in Q state, it is in the queue waiting for available resources. \n",
    "- If it is in R state, it is running. \n",
    "- If the job is no longer listed, it means it is completed.\n",
    "\n",
    "**Note**: Time spent in the queue depends on the number of users accessing the edge nodes. Once these jobs begin to run, they should take from 1 to 5 minutes to complete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
