{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Demo: Car Detection\n",
    "\n",
    "This is a sample reference implementation to showcase Object detection (car in this case) with SSD and Async API.\n",
    "Async API improves the overall frame-rate of the application by not waiting for the inference to complete but continue doing things ont he host while accelerator is busy. \n",
    "Specifically, this code demonstrates two parallel infer requests by processing the current frame while the next input frame is being captured. This essentially hides the latency of capturing.\n",
    "\n",
    "## Overview of How it works?\n",
    "The inference executable (tutorial1) reads the command line arguments and loads a network and image from the video input to the Inference Engine (IE) plugin. \n",
    "A job must be submitted to run the inference executable on a hardware accelerator (Intel® Core CPU, Intel® HD Graphics GPU, Intel® Core CPU, Intel® Movidius™ and/or Neural Compute Stick).\n",
    "After the inference is completed, the output videos are appropriately stored in the /results directory which can then be viewed within the Jupyter Notebook instance\n",
    "\n",
    "## Demonstration objectives\n",
    "* Video as input is supported using **OpenCV**\n",
    "* Inference performed actual Edge hardware\n",
    "* **OpenCV** provides the bounding boxes, labels and other information\n",
    "* Visualization of the resulting bounding boxes\n",
    "* Demonstrate the Async API in action\n",
    "\n",
    "\n",
    "## Step 1: Compile the code\n",
    "\n",
    "The code in this demo is separated into two parts.\n",
    "First part is responsible for reading the input stream and running the object detection inference workload on the stream. \n",
    "This part outputs Region Of Interest (ROI), in terms of coordinates, for each frame.\n",
    "The source code for this part can be found in [main.cpp](./main.cpp), and the executable will be named \"tutorial1\".\n",
    "Output ROI will be written into a text file, \"ROIs.txt\".\n",
    "\n",
    "The second part reads the ROIs.txt file, and overlays boxes on each frame of the stream based on the coordinates.\n",
    "Then the output video is written into a file. \n",
    "The source code for this step is in [ROI_writer.cpp](./ROI_writer.cpp).\n",
    "\n",
    "We have provided a Makefile for compiling the examples. Run the following cell to compile the application.\n",
    "(tip: use **crtl+enter** to run the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commandline flags\n",
    "\n",
    "The two executables, tutorial1 and ROIwriter, take a number of commandline arguments.\n",
    "\n",
    "Run the following cells to see the list of the available arguments: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./tutorial1 -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./ROI_writer -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Running the inference\n",
    "\n",
    "Now we are ready to run the inference workload. In this step we will be submitting the workload as a job to the job queue.\n",
    "\n",
    "Currently, you are on what is called a \"devnode\". On this system, you are alloated just one core on a large Xeon CPU. The purpose of this node is to develop code and run minimal jupyter notebooks, but it is not meant for compute jobs like deep learning inference. So we need to request additional resources from the cluster to run the inference, and this is done through the job queue.\n",
    "\n",
    "To put an item on the job queue, we must first create a bash script that run the workload we want. Run the following cell to create bash script [object_detection_job.sh](object_detection_job.sh) which will be our job script. \n",
    "\n",
    "### Writing the job script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile object_detection_job.sh\n",
    "\n",
    "# The default path for the job is your home directory, so we change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "# Object detection script writes output to a file inside a directory. We make sure that this directory exists.\n",
    "#  The output directory is the first argument of the bash script\n",
    "mkdir -p $1\n",
    "ROIFILE=$1/ROIs.txt\n",
    "OVIDEO=$1/output.mp4\n",
    "\n",
    "# Running the object detection code\n",
    "SAMPLEPATH=$PBS_O_WORKDIR\n",
    "./tutorial1 -i /data/reference-sample-data/object-detection-python/cars_1900.mp4 \\\n",
    "            -m /data/reference-sample-data/models/mobilenet-ssd/FP32/mobilenet-ssd.xml \\\n",
    "            -d $2 \\\n",
    "            -o $ROIFILE \\\n",
    "            -fr 3000 \n",
    "\n",
    "# Converting the text output to a video\n",
    "./ROI_writer -i /data/reference-sample-data/object-detection-python/cars_1900.mp4 \\\n",
    "             -o $OVIDEO \\\n",
    "             -ROIfile $ROIFILE\n",
    "             -l pascal_voc_classes.txt\n",
    "             -r 2.0 # output in half res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this script on the job queue, we use the command `qsub`.\n",
    "There are three important arguments we use with this command.\n",
    "\n",
    "First, the `-l` flag.\n",
    "This flag is used to specify what type of resources to request from the cluster.\n",
    "For example this can be used to request a Intel Xeon system, or it can be used to request a system with an FPGA.\n",
    "The syntax is `-l nodes=1:<tag>` where `<tag>` is the descriptor tag for the resource you want.\n",
    "For example, `-l nodes=1:iei-tank-xeon` will request an Intel Xeon system.\n",
    "To see the list of available tags, and the number of avilable systems, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pbsnodes | grep properties | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then there is the `-F` flag, which is used to pass in arguments to the job script.\n",
    "The [object_detection_job.sh](object_detection_job.sh) takes in 3 arguments:\n",
    "1. the path to the directory for the output video and performance stats\n",
    "2. targeted device (e.g. CPU,GPU,MYRIAD)\n",
    "3. the floating precision to use for inference\n",
    "The job scheduler will use the contents of `-F` flag as the argument to the job script.\n",
    "\n",
    "\n",
    "Finally, the `-N` flag is used to name the job itself. \n",
    "By default the jobs take on the name of the job script, which in this case would be \"object_detection_job.sh\".\n",
    "But because we are submitting these jobs with different arguments, it is useful for record-keeping to name the job differently based on the arguments.\n",
    "\n",
    "The following line will request an Intel Xeon system, passes in \"results/xeon CPU FP32\" to the job script, and names the job \"obj_det_xeon\". Run the cell to submit this job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qsub object_detection_job.sh -l nodes=1:iei-tank-xeon -F \"results/xeon CPU FP32\" -N obj_det_xeon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the jobs are done\n",
    "\n",
    "Run the following cell to bring the custom qstat widget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import demoutils\n",
    "demoutils.liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the jobs you have submitted (referenced by `Job ID`).\n",
    "It should also show the jupyter notebook job as well. \n",
    "### Before moving to step 3, make sure that all the obj_det_*  jobs submitted to the queue are completed.\n",
    "\n",
    "## Step 3: Results\n",
    "\n",
    "Once the jobs are complete, the stdout and stderr are store in files with names of the form (based on our `-N` argument):\n",
    "\n",
    "`obj_det_{type}.o{JobID}`\n",
    "\n",
    "`obj_det_{type}.e{JobID}`\n",
    "\n",
    "But for this script, the main output is the mp4 videos which are stored in the `results/` directory.\n",
    "We wrote a short utility script that will display these videos in the notebook.\n",
    "See `demoutils.py` if interested in the script.\n",
    "\n",
    "Run the following cell to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demoutils import videoHTML\n",
    "videoHTML('IEI Tank (Intel Core CPU)', 'results/xeon/output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
